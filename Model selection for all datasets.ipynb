{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKEt396_iv5U"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okF3BVjDh5OG"
      },
      "outputs": [],
      "source": [
        "pip install PyTDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qRNnuOQiNK-"
      },
      "outputs": [],
      "source": [
        "pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DorC_z3EiNIL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Lipinski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6kKvNtRiWGw"
      },
      "source": [
        "# Creating global features extractor function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYdv6Q-wiNFR"
      },
      "outputs": [],
      "source": [
        "def molecular_descriptors(table):\n",
        "\n",
        "  descriptors = pd.DataFrame()\n",
        "\n",
        "  mol = [Chem.MolFromSmiles(drug) for drug in table.Drug]\n",
        "\n",
        "  # Exact molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.ExactMolWt(i) for i in mol])\n",
        "  descriptors['Exact_MW'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan1\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan1(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan1'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan2\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan2(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan2'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan3\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan3(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan3'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule ignoring hydrogens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.HeavyAtomMolWt(i) for i in mol])\n",
        "  descriptors['HeavyAtomMolWt'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MinAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinPartialCharge(i) for i in mol])\n",
        "  descriptors['MinPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolWt(i) for i in mol])\n",
        "  descriptors['MolWt'] = Nilavo[0]\n",
        "\n",
        "  # Number of radical electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumRadicalElectrons(i) for i in mol])\n",
        "  descriptors['NumRadicalElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Number of valence electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumValenceElectrons(i) for i in mol])\n",
        "  descriptors['NumValenceElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Log of partition coefficient\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolLogP(i) for i in mol])\n",
        "  descriptors['Partition_Coefficient'] = Nilavo[0]\n",
        "\n",
        "\n",
        "  ### Lipinski Descriptors ###\n",
        "  # Fraction of C atoms that are SP3 hybridized\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.FractionCSP3(i) for i in mol])\n",
        "  descriptors['FractionCSP3'] = Nilavo[0]\n",
        "\n",
        "  # Number of heavy atoms a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.HeavyAtomCount(i) for i in mol])\n",
        "  descriptors['Heavy_atoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of NHs or OHs\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NHOHCount(i) for i in mol])\n",
        "  descriptors['NHs/OHs'] = Nilavo[0]\n",
        "\n",
        "  # Number of Nitrogens and Oxygens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NOCount(i) for i in mol])\n",
        "  descriptors['N&O'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticRings(i) for i in mol])\n",
        "  descriptors['Aliphatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Nmber of aromatic carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticRings(i) for i in mol])\n",
        "  descriptors['Aromatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Acceptors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHAcceptors(i) for i in mol])\n",
        "  descriptors['HAcceptors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Donors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHDonors(i) for i in mol])\n",
        "  descriptors['HDonors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Heteroatoms\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHeteroatoms(i) for i in mol])\n",
        "  descriptors['Heteroatoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of Rotatable Bonds\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumRotatableBonds(i) for i in mol])\n",
        "  descriptors['Rotatable_Bonds'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedCarbocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedHeterocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedRings(i) for i in mol])\n",
        "  descriptors['Saturated_Rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.RingCount(i) for i in mol])\n",
        "  descriptors['Rings'] = Nilavo[0]\n",
        "\n",
        "  return descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cWmU7Xwi3-2"
      },
      "source": [
        "# Regression Problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj6FJ81CiNCq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6FCMuNAkYUT"
      },
      "outputs": [],
      "source": [
        "regression_datasets = ['caco2_wang', \n",
        "                       'lipophilicity_astrazeneca', \n",
        "                       'solubility_aqsoldb', \n",
        "                       'ppbr_az', \n",
        "                       'vdss_lombardo', \n",
        "                       'half_life_obach', \n",
        "                       'clearance_microsome_az',\n",
        "                       'clearance_hepatocyte_az', \n",
        "                       'ld50_zhu'\n",
        "                      ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M7NOMK-i_U0"
      },
      "source": [
        "* Search best ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txds884-i8bN",
        "outputId": "e0109b36-84a1-43f7-ac11-08281b512a09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Benchmark Group...\n",
            "100%|██████████| 1.47M/1.47M [00:00<00:00, 20.4MiB/s]\n",
            "Extracting zip file...\n",
            "Done!\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 831.26it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:03<00:00, 858.79it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4923.60it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2491.33it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1956.94it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2338.02it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2443.57it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2359.12it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5660.94it/s]\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "best_model_list = []\n",
        "\n",
        "for reg_data in regression_datasets:\n",
        "  LR = []\n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  GB = []\n",
        "  AB = []\n",
        "\n",
        "  benchmark = group.get(reg_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "  train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = 1)\n",
        "\n",
        "  # feature extracting\n",
        "  x_train = molecular_descriptors(train)\n",
        "  x_valid = molecular_descriptors(valid)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train = np.nan_to_num(x_train, nan=0, posinf=0)\n",
        "  x_valid = np.nan_to_num(x_valid, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train = train.Y\n",
        "  y_valid = valid.Y\n",
        "\n",
        "  ### USE ONLY TRAINING AND VALIDATION SET TO SELECT MODEL ###\n",
        "\n",
        "  lin = LinearRegression()\n",
        "  lin.fit(x_train, y_train)\n",
        "  y_pred_valid = lin.predict(x_valid)\n",
        "  LR.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  knn = KNeighborsRegressor()\n",
        "  knn.fit(x_train, y_train)\n",
        "  y_pred_valid = knn.predict(x_valid)\n",
        "  KNN.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  dt = DecisionTreeRegressor(random_state=0)\n",
        "  dt.fit(x_train, y_train)\n",
        "  y_pred_valid = dt.predict(x_valid)\n",
        "  DT.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  bag = BaggingRegressor(DecisionTreeRegressor(), random_state=0)\n",
        "  bag.fit(x_train, y_train)\n",
        "  y_pred_valid = bag.predict(x_valid)\n",
        "  Bag.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  rf = RandomForestRegressor(random_state=0)\n",
        "  rf.fit(x_train, y_train)\n",
        "  y_pred_valid = rf.predict(x_valid)\n",
        "  RF.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  et = ExtraTreesRegressor(random_state=0)\n",
        "  et.fit(x_train, y_train)\n",
        "  y_pred_valid = et.predict(x_valid)\n",
        "  ET.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  grad = GradientBoostingRegressor(random_state=0)\n",
        "  grad.fit(x_train, y_train)\n",
        "  y_pred_valid = grad.predict(x_valid)\n",
        "  GB.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  ada = AdaBoostRegressor(DecisionTreeRegressor(),random_state=0)\n",
        "  ada.fit(x_train, y_train)\n",
        "  y_pred_valid = ada.predict(x_valid)\n",
        "  AB.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  # Find out which model gives lowest MAE\n",
        "  m = []\n",
        "  models = ['Linear', 'K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Gradient_Boosting', 'Ada_Boost']\n",
        "  for ml_mae in [LR, KNN, DT, Bag, RF, ET, GB, AB]:\n",
        "    m.append(ml_mae)\n",
        "  m = pd.Series(m, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  mae_tune = []\n",
        "  best_model_store = []\n",
        "\n",
        "  for low_mae in [0, 1, 2]:\n",
        "      best_model_name = m[m == np.sort(m)[low_mae][0]].index[0]\n",
        "\n",
        "      ml_model = [lin, knn, dt, bag, rf, et, grad, ada]\n",
        "      best_model = ml_model[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Linear':\n",
        "        best_model = LinearRegression()\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(LR[0])\n",
        "\n",
        "      elif best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeRegressor(random_state=0)\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsRegressor(n_neighbors = best_param)\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        mae_tune.append(mae(y_valid, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingRegressor(DecisionTreeRegressor(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestRegressor(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesRegressor(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        mae_tune.append(mae(y_valid, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Gradient_Boosting':\n",
        "          best_model = GradientBoostingRegressor(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        mae_tune.append(mae(y_valid, y_p))\n",
        "\n",
        "  mae_tune_series = pd.Series(mae_tune, index = best_model_store)\n",
        "\n",
        "  best_model = mae_tune_series[mae_tune_series == min(mae_tune_series)].index[0]\n",
        "  best_model_list.append(best_model)\n",
        "\n",
        "best_model_series = pd.Series(best_model_list, index = regression_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvTJPi99kfk-",
        "outputId": "d733a1f6-a4c0-42f8-e658-9a09388fd75d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "caco2_wang                   AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "lipophilicity_astrazeneca    AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "solubility_aqsoldb           AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "ppbr_az                      GradientBoostingRegressor(learning_rate=0.005,...\n",
              "vdss_lombardo                AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "half_life_obach              AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "clearance_microsome_az       AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "clearance_hepatocyte_az      ExtraTreesRegressor(n_estimators=500, random_s...\n",
              "ld50_zhu                     ExtraTreesRegressor(n_estimators=350, random_s...\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9YHs2XAkgJx",
        "outputId": "a7dd3578-f426-459f-dbb0-fc8c8f2af745"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
              "                   n_estimators=500, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.3,\n",
              "                   n_estimators=500, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
              "                   n_estimators=450, random_state=0),\n",
              " GradientBoostingRegressor(learning_rate=0.005, n_estimators=500, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.005,\n",
              "                   n_estimators=200, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.08,\n",
              "                   n_estimators=350, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.3,\n",
              "                   n_estimators=350, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=500, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=350, random_state=0)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0wMfKcpkrZO"
      },
      "source": [
        "# Classification Problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tFKCIQikiTd"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score as acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu-3Vhe2lBKR"
      },
      "outputs": [],
      "source": [
        "classification_datasets = ['hia_hou', \n",
        "                       'pgp_broccatelli', \n",
        "                       'bioavailability_ma', \n",
        "                       'bbb_martins', \n",
        "                       'cyp2d6_veith', \n",
        "                       'cyp3a4_veith', \n",
        "                       'cyp2c9_veith',\n",
        "                       'cyp2d6_substrate_carbonmangels', \n",
        "                       'cyp3a4_substrate_carbonmangels',\n",
        "                       'cyp2c9_substrate_carbonmangels',\n",
        "                       'herg',\n",
        "                       'ames',\n",
        "                       'dili'\n",
        "                       ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9SZryP2k3IC"
      },
      "source": [
        "* Search best ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfaUohSak0Zf",
        "outputId": "45764b66-ba04-4f95-a490-97bf0dbfe253"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found local copy...\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3279.83it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2633.32it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3114.05it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2851.14it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2761.57it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2961.92it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2886.68it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 3088.80it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2934.64it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2864.14it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2752.37it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4939.58it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3314.49it/s]\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "best_Cmodel_list = []\n",
        "\n",
        "for clf_data in classification_datasets:\n",
        "  \n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  AB = []\n",
        "  XG = []\n",
        "\n",
        "  benchmark = group.get(clf_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "  train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = 1)\n",
        "\n",
        "  # feature extracting\n",
        "  x_train = molecular_descriptors(train)\n",
        "  x_valid = molecular_descriptors(valid)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train = np.nan_to_num(x_train, nan=0, posinf=0)\n",
        "  x_valid = np.nan_to_num(x_valid, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train = train.Y\n",
        "  y_valid = valid.Y\n",
        "\n",
        "  ### USE ONLY TRAINING AND VALIDATION SET TO SELECT MODEL ###\n",
        "\n",
        "  # neighbors\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn.fit(x_train, y_train)\n",
        "  y_pred_valid = knn.predict(x_valid)\n",
        "  KNN.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  # tree\n",
        "  dt = DecisionTreeClassifier(random_state=0)\n",
        "  dt.fit(x_train, y_train)\n",
        "  y_pred_valid = dt.predict(x_valid)\n",
        "  DT.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  # ensemble\n",
        "  bag = BaggingClassifier(DecisionTreeClassifier(), random_state=0)\n",
        "  bag.fit(x_train, y_train)\n",
        "  y_pred_valid = bag.predict(x_valid)\n",
        "  Bag.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  rf = RandomForestClassifier(random_state=0)\n",
        "  rf.fit(x_train, y_train)\n",
        "  y_pred_valid = rf.predict(x_valid)\n",
        "  RF.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  et = ExtraTreesClassifier(random_state=0)\n",
        "  et.fit(x_train, y_train)\n",
        "  y_pred_valid = et.predict(x_valid)\n",
        "  ET.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  ada = AdaBoostClassifier(DecisionTreeClassifier(),random_state=0)\n",
        "  ada.fit(x_train, y_train)\n",
        "  y_pred_valid = ada.predict(x_valid)\n",
        "  AB.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  xg = XGBClassifier(random_state=0)\n",
        "  xg.fit(x_train, y_train)\n",
        "  y_pred_valid = xg.predict(x_valid)\n",
        "  XG.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  # Find out which model gives highest accuracy\n",
        "  a = []\n",
        "  models = ['K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Ada_Boost', 'XG_Boost']\n",
        "\n",
        "  for ml_acc in [KNN, DT, Bag, RF, ET, AB, XG]:\n",
        "    a.append(ml_acc)\n",
        "  a = pd.Series(a, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  acc_tune = []\n",
        "  best_Cmodel_store = []\n",
        "\n",
        "  for high_acc in [-1, -2]:\n",
        "      best_model_name = a[a == np.sort(a)[high_acc][0]].index[0]\n",
        "\n",
        "      ml_Cmodel = [knn, dt, bag, rf, et, ada, xg]\n",
        "      best_model = ml_Cmodel[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeClassifier(random_state=0)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "        acc_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsClassifier(n_neighbors = best_param)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        acc_tune.append(acc(y_valid, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestClassifier(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesClassifier(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        acc_tune.append(acc(y_valid, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Ada_Boost':\n",
        "          best_model = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = XGBClassifier(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "          \n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        acc_tune.append(acc(y_valid, y_p))\n",
        "\n",
        "  acc_tune_series = pd.Series(acc_tune, index = best_Cmodel_store)\n",
        "\n",
        "  best_Cmodel = acc_tune_series[acc_tune_series == max(acc_tune_series)].index[0]\n",
        "  best_Cmodel_list.append(best_model)\n",
        "\n",
        "best_Cmodel_series = pd.Series(best_Cmodel_list, index = classification_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSDzYjuElKr6",
        "outputId": "18680c5e-5de4-456b-c0bb-3d535e3bb7b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "hia_hou                           BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "pgp_broccatelli                   ExtraTreesClassifier(n_estimators=500, random_...\n",
              "bioavailability_ma                RandomForestClassifier(n_estimators=400, rando...\n",
              "bbb_martins                       BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "cyp2d6_veith                      ExtraTreesClassifier(n_estimators=250, random_...\n",
              "cyp3a4_veith                                        XGBClassifier(n_estimators=400)\n",
              "cyp2c9_veith                      BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "cyp2d6_substrate_carbonmangels    BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "cyp3a4_substrate_carbonmangels    XGBClassifier(learning_rate=0.005, n_estimator...\n",
              "cyp2c9_substrate_carbonmangels    BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "herg                              BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "ames                              ExtraTreesClassifier(n_estimators=500, random_...\n",
              "dili                                            KNeighborsClassifier(n_neighbors=4)\n",
              "dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_Cmodel_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlk04wyNlLH2",
        "outputId": "3834b9ba-b514-4789-ec50-44204e932d0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=200,\n",
              "                   random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=500, random_state=0),\n",
              " RandomForestClassifier(n_estimators=400, random_state=0),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100,\n",
              "                   random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=250, random_state=0),\n",
              " XGBClassifier(n_estimators=400),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=350,\n",
              "                   random_state=0),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=250,\n",
              "                   random_state=0),\n",
              " XGBClassifier(learning_rate=0.005, n_estimators=150),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500,\n",
              "                   random_state=0),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=150,\n",
              "                   random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=500, random_state=0),\n",
              " KNeighborsClassifier(n_neighbors=4)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_Cmodel_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c7_OGcJiJM4"
      },
      "source": [
        "# Save selected best models for all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOao-EVsh6mW"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giE4iMVih9Gk"
      },
      "outputs": [],
      "source": [
        "# save selected models for regression datasets\n",
        "pickle.dump(best_model_series,open('best_model_series.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTiE061sh_Sf"
      },
      "outputs": [],
      "source": [
        "# save selected models for classification datasets\n",
        "pickle.dump(best_Cmodel_series,open('best_Cmodel_series.pkl','wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| **Dataset**                    | Model                                                                                                            |\n",
        "| ------------------------------ | ---------------------------------------------------------------------------------------------------------------- |\n",
        "| *`ABSORPTION`*                                                                                                                                    |\n",
        "| caco2_wang                     | AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2, n_estimators=500, random_state=0)   |\n",
        "| hia_hou                        | BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=200, random_state=0)                     |\n",
        "| pgp_broccatelli                | ExtraTreesClassifier(n_estimators=500, random_state=0)                                                           |\n",
        "| bioavailability_ma             | RandomForestClassifier(n_estimators=400, random_state=0)                                                         |\n",
        "| lipophilicity_astrazeneca      | AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.3, n_estimators=500, random_state=0)   |\n",
        "| solubility_aqsoldb             | AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2, n_estimators=450, random_state=0)   |\n",
        "| *`DISTRIBUTION`*                                                                                                                                  |\n",
        "| bbb_martins                    | BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=0)                     |\n",
        "| ppbr_az                        | GradientBoostingRegressor(learning_rate=0.005, n_estimators=500, random_state=0)                                 |\n",
        "| vdss_lombardo                  | AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.005, n_estimators=200, random_state=0) |\n",
        "| *`METABOLISM`*                                                                                                                                    |\n",
        "| cyp2d6_veith                   | ExtraTreesClassifier(n_estimators=250, random_state=0)                                                           |\n",
        "| cyp3a4_veith                   | XGBClassifier(n_estimators=400)                                                                                  |\n",
        "| cyp2c9_veith                   | BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=350, random_state=0)                     |\n",
        "| cyp2d6_substrate_carbonmangels | BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=250, random_state=0)                     |\n",
        "| cyp3a4_substrate_carbonmangels | XGBClassifier(learning_rate=0.005, n_estimators=150)                                                             |\n",
        "| cyp2c9_substrate_carbonmangels | BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500, random_state=0)                     |\n",
        "| *`EXCRETION`*                                                                                                                                     |\n",
        "| half_life_obach                | AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.08, n_estimators=350, random_state=0)  |\n",
        "| clearance_microsome_az         | AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.3, n_estimators=350, random_state=0)   |\n",
        "| clearance_hepatocyte_az        | ExtraTreesRegressor(n_estimators=500, random_state=0)                                                            |\n",
        "| *`TOXICITY`*                                                                                                                                      |\n",
        "| herg                           | BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=150, random_state=0)                     |\n",
        "| ames                           | ExtraTreesClassifier(n_estimators=500, random_state=0)                                                           |\n",
        "| dili                           | KNeighborsClassifier(n_neighbors=4)                                                                              |\n",
        "| ld50_zhu                       | ExtraTreesRegressor(n_estimators=350, random_state=0)                                                            |"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ADMET Properties Prediction Using Descriptors.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
