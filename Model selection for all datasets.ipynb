{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKEt396_iv5U"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "okF3BVjDh5OG"
      },
      "outputs": [],
      "source": [
        "pip install PyTDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4qRNnuOQiNK-"
      },
      "outputs": [],
      "source": [
        "pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DorC_z3EiNIL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Lipinski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6kKvNtRiWGw"
      },
      "source": [
        "# Creating global features extractor function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZYdv6Q-wiNFR"
      },
      "outputs": [],
      "source": [
        "def molecular_descriptors(table):\n",
        "\n",
        "  descriptors = pd.DataFrame()\n",
        "\n",
        "  mol = [Chem.MolFromSmiles(drug) for drug in table.Drug]\n",
        "\n",
        "  # Exact molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.ExactMolWt(i) for i in mol])\n",
        "  descriptors['Exact_MW'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan1\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan1(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan1'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan2\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan2(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan2'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan3\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan3(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan3'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule ignoring hydrogens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.HeavyAtomMolWt(i) for i in mol])\n",
        "  descriptors['HeavyAtomMolWt'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MinAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinPartialCharge(i) for i in mol])\n",
        "  descriptors['MinPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolWt(i) for i in mol])\n",
        "  descriptors['MolWt'] = Nilavo[0]\n",
        "\n",
        "  # Number of radical electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumRadicalElectrons(i) for i in mol])\n",
        "  descriptors['NumRadicalElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Number of valence electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumValenceElectrons(i) for i in mol])\n",
        "  descriptors['NumValenceElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Log of partition coefficient\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolLogP(i) for i in mol])\n",
        "  descriptors['Partition_Coefficient'] = Nilavo[0]\n",
        "\n",
        "\n",
        "  ### Lipinski Descriptors ###\n",
        "  # Fraction of C atoms that are SP3 hybridized\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.FractionCSP3(i) for i in mol])\n",
        "  descriptors['FractionCSP3'] = Nilavo[0]\n",
        "\n",
        "  # Number of heavy atoms a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.HeavyAtomCount(i) for i in mol])\n",
        "  descriptors['Heavy_atoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of NHs or OHs\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NHOHCount(i) for i in mol])\n",
        "  descriptors['NHs/OHs'] = Nilavo[0]\n",
        "\n",
        "  # Number of Nitrogens and Oxygens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NOCount(i) for i in mol])\n",
        "  descriptors['N&O'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticRings(i) for i in mol])\n",
        "  descriptors['Aliphatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Nmber of aromatic carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticRings(i) for i in mol])\n",
        "  descriptors['Aromatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Acceptors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHAcceptors(i) for i in mol])\n",
        "  descriptors['HAcceptors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Donors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHDonors(i) for i in mol])\n",
        "  descriptors['HDonors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Heteroatoms\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHeteroatoms(i) for i in mol])\n",
        "  descriptors['Heteroatoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of Rotatable Bonds\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumRotatableBonds(i) for i in mol])\n",
        "  descriptors['Rotatable_Bonds'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedCarbocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedHeterocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedRings(i) for i in mol])\n",
        "  descriptors['Saturated_Rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.RingCount(i) for i in mol])\n",
        "  descriptors['Rings'] = Nilavo[0]\n",
        "\n",
        "  return descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cWmU7Xwi3-2"
      },
      "source": [
        "# Regression Problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rj6FJ81CiNCq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K6FCMuNAkYUT"
      },
      "outputs": [],
      "source": [
        "regression_datasets = ['caco2_wang', \n",
        "                       'lipophilicity_astrazeneca', \n",
        "                       'solubility_aqsoldb', \n",
        "                       'ppbr_az', \n",
        "                       'vdss_lombardo', \n",
        "                       'half_life_obach', \n",
        "                       'clearance_microsome_az',\n",
        "                       'clearance_hepatocyte_az', \n",
        "                       'ld50_zhu'\n",
        "                      ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M7NOMK-i_U0"
      },
      "source": [
        "* Search best ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txds884-i8bN",
        "outputId": "8008754d-fef2-493a-d18a-3c702addf128"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Benchmark Group...\n",
            "100%|██████████| 1.47M/1.47M [00:00<00:00, 12.2MiB/s]\n",
            "Extracting zip file...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "best_model_list = []\n",
        "\n",
        "for reg_data in regression_datasets:\n",
        "  LR = []\n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  GB = []\n",
        "  AB = []\n",
        "\n",
        "  benchmark = group.get(reg_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "  # feature extracting\n",
        "  x_train_val = molecular_descriptors(train_val)\n",
        "  x_test = molecular_descriptors(test)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train_val = np.nan_to_num(x_train_val, nan=0, posinf=0)\n",
        "  x_test = np.nan_to_num(x_test, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train_val = train_val.Y\n",
        "  y_test = test.Y\n",
        "\n",
        "  lin = LinearRegression()\n",
        "  lin.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = lin.predict(x_test)\n",
        "  LR.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  knn = KNeighborsRegressor()\n",
        "  knn.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = knn.predict(x_test)\n",
        "  KNN.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  dt = DecisionTreeRegressor(random_state=0)\n",
        "  dt.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = dt.predict(x_test)\n",
        "  DT.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  bag = BaggingRegressor(DecisionTreeRegressor(), random_state=0)\n",
        "  bag.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = bag.predict(x_test)\n",
        "  Bag.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  rf = RandomForestRegressor(random_state=0)\n",
        "  rf.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = rf.predict(x_test)\n",
        "  RF.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  et = ExtraTreesRegressor(random_state=0)\n",
        "  et.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = et.predict(x_test)\n",
        "  ET.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  grad = GradientBoostingRegressor(random_state=0)\n",
        "  grad.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = grad.predict(x_test)\n",
        "  GB.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  ada = AdaBoostRegressor(DecisionTreeRegressor(),random_state=0)\n",
        "  ada.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = ada.predict(x_test)\n",
        "  AB.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  # Find out which model gives lowest MAE\n",
        "  m = []\n",
        "  models = ['Linear', 'K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Gradient_Boosting', 'Ada_Boost']\n",
        "  for ml_mae in [LR, KNN, DT, Bag, RF, ET, GB, AB]:\n",
        "    m.append(ml_mae)\n",
        "  m = pd.Series(m, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  mae_tune = []\n",
        "  best_model_store = []\n",
        "\n",
        "  for low_mae in [0, 1, 2]:\n",
        "      best_model_name = m[m == np.sort(m)[low_mae][0]].index[0]\n",
        "\n",
        "      ml_model = [lin, knn, dt, bag, rf, et, grad, ada]\n",
        "      best_model = ml_model[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Linear':\n",
        "        best_model = LinearRegression()\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(LR[0])\n",
        "\n",
        "      elif best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeRegressor(random_state=0)\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsRegressor(n_neighbors = best_param)\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        mae_tune.append(mae(y_test, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingRegressor(DecisionTreeRegressor(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestRegressor(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesRegressor(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        mae_tune.append(mae(y_test, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Gradient_Boosting':\n",
        "          best_model = GradientBoostingRegressor(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        mae_tune.append(mae(y_test, y_p))\n",
        "\n",
        "  mae_tune_series = pd.Series(mae_tune, index = best_model_store)\n",
        "\n",
        "  best_model = mae_tune_series[mae_tune_series == min(mae_tune_series)].index[0]\n",
        "  best_model_list.append(best_model)\n",
        "\n",
        "best_model_series = pd.Series(best_model_list, index = regression_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvTJPi99kfk-",
        "outputId": "98d16309-7316-4ef3-915c-9afbbc989de5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "caco2_wang                   GradientBoostingRegressor(learning_rate=0.08, ...\n",
              "lipophilicity_astrazeneca    AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "solubility_aqsoldb           ExtraTreesRegressor(n_estimators=400, random_s...\n",
              "ppbr_az                      ExtraTreesRegressor(n_estimators=450, random_s...\n",
              "vdss_lombardo                AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "half_life_obach              AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "clearance_microsome_az       AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "clearance_hepatocyte_az      ExtraTreesRegressor(n_estimators=350, random_s...\n",
              "ld50_zhu                     RandomForestRegressor(n_estimators=400, random...\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9YHs2XAkgJx",
        "outputId": "db542eae-935e-4c06-d544-edd9d613fa5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[GradientBoostingRegressor(learning_rate=0.08, n_estimators=200, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
              "                   n_estimators=450, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=400, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=450, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.3,\n",
              "                   n_estimators=400, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.05,\n",
              "                   n_estimators=300, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.05,\n",
              "                   n_estimators=400, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=350, random_state=0),\n",
              " RandomForestRegressor(n_estimators=400, random_state=0)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0wMfKcpkrZO"
      },
      "source": [
        "# Classification Problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0tFKCIQikiTd"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score as acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bu-3Vhe2lBKR"
      },
      "outputs": [],
      "source": [
        "classification_datasets = ['hia_hou', \n",
        "                       'pgp_broccatelli', \n",
        "                       'bioavailability_ma', \n",
        "                       'bbb_martins', \n",
        "                       'cyp2d6_veith', \n",
        "                       'cyp3a4_veith', \n",
        "                       'cyp2c9_veith',\n",
        "                       'cyp2d6_substrate_carbonmangels', \n",
        "                       'cyp3a4_substrate_carbonmangels',\n",
        "                       'cyp2c9_substrate_carbonmangels',\n",
        "                       'herg',\n",
        "                       'ames',\n",
        "                       'dili'\n",
        "                       ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9SZryP2k3IC"
      },
      "source": [
        "* Search best ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfaUohSak0Zf",
        "outputId": "3c0d2c9d-df17-48fc-e4d8-1beded9d757b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Benchmark Group...\n",
            "100%|██████████| 1.47M/1.47M [00:00<00:00, 2.45MiB/s]\n",
            "Extracting zip file...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "best_Cmodel_list = []\n",
        "\n",
        "for clf_data in classification_datasets:\n",
        "  \n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  AB = []\n",
        "  XG = []\n",
        "\n",
        "  benchmark = group.get(clf_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "  # feature extracting\n",
        "  x_train_val = molecular_descriptors(train_val)\n",
        "  x_test = molecular_descriptors(test)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train_val = np.nan_to_num(x_train_val, nan=0, posinf=0)\n",
        "  x_test = np.nan_to_num(x_test, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train_val = train_val.Y\n",
        "  y_test = test.Y\n",
        "\n",
        "  # neighbors\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = knn.predict(x_test)\n",
        "  KNN.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  # tree\n",
        "  dt = DecisionTreeClassifier(random_state=0)\n",
        "  dt.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = dt.predict(x_test)\n",
        "  DT.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  # ensemble\n",
        "  bag = BaggingClassifier(DecisionTreeClassifier(), random_state=0)\n",
        "  bag.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = bag.predict(x_test)\n",
        "  Bag.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  rf = RandomForestClassifier(random_state=0)\n",
        "  rf.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = rf.predict(x_test)\n",
        "  RF.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  et = ExtraTreesClassifier(random_state=0)\n",
        "  et.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = et.predict(x_test)\n",
        "  ET.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  ada = AdaBoostClassifier(DecisionTreeClassifier(),random_state=0)\n",
        "  ada.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = ada.predict(x_test)\n",
        "  AB.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  xg = XGBClassifier(random_state=0)\n",
        "  xg.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = xg.predict(x_test)\n",
        "  XG.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  # Find out which model gives highest accuracy\n",
        "  a = []\n",
        "  models = ['K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Ada_Boost', 'XG_Boost']\n",
        "\n",
        "  for ml_acc in [KNN, DT, Bag, RF, ET, AB, XG]:\n",
        "    a.append(ml_acc)\n",
        "  a = pd.Series(a, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  acc_tune = []\n",
        "  best_Cmodel_store = []\n",
        "\n",
        "  for high_acc in [-1, -2]:\n",
        "      best_model_name = a[a == np.sort(a)[high_acc][0]].index[0]\n",
        "\n",
        "      ml_Cmodel = [knn, dt, bag, rf, et, ada, xg]\n",
        "      best_model = ml_Cmodel[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeClassifier(random_state=0)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "        acc_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsClassifier(n_neighbors = best_param)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        acc_tune.append(acc(y_test, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestClassifier(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesClassifier(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        acc_tune.append(acc(y_test, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Ada_Boost':\n",
        "          best_model = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = XGBClassifier(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "          \n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        acc_tune.append(acc(y_test, y_p))\n",
        "\n",
        "  acc_tune_series = pd.Series(acc_tune, index = best_Cmodel_store)\n",
        "\n",
        "  best_Cmodel = acc_tune_series[acc_tune_series == max(acc_tune_series)].index[0]\n",
        "  best_Cmodel_list.append(best_model)\n",
        "\n",
        "best_Cmodel_series = pd.Series(best_Cmodel_list, index = classification_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSDzYjuElKr6",
        "outputId": "e3a0be79-35d2-4a72-dcc4-c01bfdccc10d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "hia_hou                                      DecisionTreeClassifier(random_state=0)\n",
              "pgp_broccatelli                   ExtraTreesClassifier(n_estimators=250, random_...\n",
              "bioavailability_ma                ExtraTreesClassifier(n_estimators=450, random_...\n",
              "bbb_martins                                    ExtraTreesClassifier(random_state=0)\n",
              "cyp2d6_veith                      RandomForestClassifier(n_estimators=250, rando...\n",
              "cyp3a4_veith                      ExtraTreesClassifier(n_estimators=450, random_...\n",
              "cyp2c9_veith                      AdaBoostClassifier(base_estimator=DecisionTree...\n",
              "cyp2d6_substrate_carbonmangels    BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "cyp3a4_substrate_carbonmangels               RandomForestClassifier(random_state=0)\n",
              "cyp2c9_substrate_carbonmangels    ExtraTreesClassifier(n_estimators=150, random_...\n",
              "herg                              ExtraTreesClassifier(n_estimators=350, random_...\n",
              "ames                              RandomForestClassifier(n_estimators=500, rando...\n",
              "dili                              RandomForestClassifier(n_estimators=500, rando...\n",
              "dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_Cmodel_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlk04wyNlLH2",
        "outputId": "d9bd0778-8c04-44bb-95b8-712089904d2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[DecisionTreeClassifier(random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=250, random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=450, random_state=0),\n",
              " ExtraTreesClassifier(random_state=0),\n",
              " RandomForestClassifier(n_estimators=250, random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=450, random_state=0),\n",
              " AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=0.3,\n",
              "                    n_estimators=400, random_state=0),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=150,\n",
              "                   random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=150, random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=350, random_state=0),\n",
              " RandomForestClassifier(n_estimators=500, random_state=0),\n",
              " RandomForestClassifier(n_estimators=500, random_state=0)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_Cmodel_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save selected best models for all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lRUv_JChV4m0"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gUucDM5HV4kJ"
      },
      "outputs": [],
      "source": [
        "# save selected models for regression datasets\n",
        "pickle.dump(best_model_series,open('best_model_series.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LLV_UuTWV4hS"
      },
      "outputs": [],
      "source": [
        "# save selected models for classification datasets\n",
        "pickle.dump(best_Cmodel_series,open('best_Cmodel_series.pkl','wb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ADMET Properties Prediction Using Descriptors.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
