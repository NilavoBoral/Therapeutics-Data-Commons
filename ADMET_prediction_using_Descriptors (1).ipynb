{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1z62cABYLKi"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_pW859fofORJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86364iY4YeUx"
      },
      "outputs": [],
      "source": [
        "pip install PyTDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHRsVLy2YQ2U"
      },
      "outputs": [],
      "source": [
        "pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4FdAhP6YkCY"
      },
      "source": [
        "# Creating feature extractor function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woDFpYK1Ye16"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Lipinski"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCkayeomYnyV"
      },
      "outputs": [],
      "source": [
        "# 27 molecular descriptors\n",
        "\n",
        "def molecular_descriptors(table):\n",
        "\n",
        "  descriptors = pd.DataFrame()\n",
        "\n",
        "  mol = [Chem.MolFromSmiles(drug) for drug in table.Drug]\n",
        "\n",
        "  # Exact molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.ExactMolWt(i) for i in mol])\n",
        "  descriptors['Exact_MW'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan1\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan1(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan1'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan2\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan2(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan2'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan3\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan3(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan3'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule ignoring hydrogens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.HeavyAtomMolWt(i) for i in mol])\n",
        "  descriptors['HeavyAtomMolWt'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolWt(i) for i in mol])\n",
        "  descriptors['MolWt'] = Nilavo[0]\n",
        "\n",
        "  # Number of radical electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumRadicalElectrons(i) for i in mol])\n",
        "  descriptors['NumRadicalElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Number of valence electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumValenceElectrons(i) for i in mol])\n",
        "  descriptors['NumValenceElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Log of partition coefficient\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolLogP(i) for i in mol])\n",
        "  descriptors['Partition_Coefficient'] = Nilavo[0]\n",
        "\n",
        "\n",
        "  ### Lipinski Descriptors ###\n",
        "  # Fraction of C atoms that are SP3 hybridized\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.FractionCSP3(i) for i in mol])\n",
        "  descriptors['FractionCSP3'] = Nilavo[0]\n",
        "\n",
        "  # Number of heavy atoms a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.HeavyAtomCount(i) for i in mol])\n",
        "  descriptors['Heavy_atoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of NHs or OHs\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NHOHCount(i) for i in mol])\n",
        "  descriptors['NHs/OHs'] = Nilavo[0]\n",
        "\n",
        "  # Number of Nitrogens and Oxygens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NOCount(i) for i in mol])\n",
        "  descriptors['N&O'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticRings(i) for i in mol])\n",
        "  descriptors['Aliphatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Nmber of aromatic carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticRings(i) for i in mol])\n",
        "  descriptors['Aromatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Acceptors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHAcceptors(i) for i in mol])\n",
        "  descriptors['HAcceptors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Donors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHDonors(i) for i in mol])\n",
        "  descriptors['HDonors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Heteroatoms\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHeteroatoms(i) for i in mol])\n",
        "  descriptors['Heteroatoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of Rotatable Bonds\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumRotatableBonds(i) for i in mol])\n",
        "  descriptors['Rotatable_Bonds'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedCarbocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedHeterocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedRings(i) for i in mol])\n",
        "  descriptors['Saturated_Rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.RingCount(i) for i in mol])\n",
        "  descriptors['Rings'] = Nilavo[0]\n",
        "\n",
        "  return descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39-nKuXCYv5z"
      },
      "source": [
        "# Choosing best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TqKCYkPXqUn"
      },
      "source": [
        "Regression data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjuEe68AYtEf"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "\n",
        "from sklearn.metrics import r2_score as r2\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error as mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAsCtFVLYghP"
      },
      "outputs": [],
      "source": [
        "regression_datasets = ['caco2_wang', \n",
        "                       'lipophilicity_astrazeneca', \n",
        "                       'solubility_aqsoldb', \n",
        "                       'ppbr_az', \n",
        "                       'vdss_lombardo', \n",
        "                       'half_life_obach', \n",
        "                       'clearance_microsome_az',\n",
        "                       'clearance_hepatocyte_az', \n",
        "                       'ld50_zhu']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KmRLtktVGSE",
        "outputId": "3fb6a5c3-9f8e-4700-f2c2-753b69db1918"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Benchmark Group...\n",
            "100%|██████████| 1.47M/1.47M [00:00<00:00, 12.6MiB/s]\n",
            "Extracting zip file...\n",
            "Done!\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 1203.61it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2408.39it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2367.55it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2456.87it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2358.69it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2546.83it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:02<00:00, 1445.35it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2548.49it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:04<00:00, 771.68it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2624.64it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4859.11it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:04<00:00, 1784.73it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4783.57it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4836.89it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4942.39it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2462.53it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2507.89it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2446.87it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2423.75it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2428.56it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1835.13it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1853.85it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1873.80it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1927.39it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1772.73it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2206.29it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2233.49it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 1887.24it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2254.43it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2199.54it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2309.98it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2353.76it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2305.80it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2143.17it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2385.24it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2251.58it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2409.28it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2391.54it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2254.71it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2435.52it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5605.39it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5675.07it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5690.97it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5607.71it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5542.10it/s]\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "\n",
        "best_model_list = []\n",
        "best_model_store = []\n",
        "\n",
        "for reg_data in regression_datasets:\n",
        "  \n",
        "  LR = []\n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  GB = []\n",
        "  AB = []\n",
        "\n",
        "  for seed in np.arange(1,6):\n",
        "    benchmark = group.get(reg_data)\n",
        "    name = benchmark['name']\n",
        "\n",
        "    # split the dataset into train_val & test set\n",
        "    train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "    # split the train_val set into train & validation set\n",
        "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'scaffold', seed = seed)\n",
        "\n",
        "      ### I will only use train & valid set to find the best model.\n",
        "      ### And test set will be used as indipendent test set to generalise my best model's performance.\n",
        "\n",
        "    # feature extracting\n",
        "    x_train = molecular_descriptors(train)\n",
        "    x_valid = molecular_descriptors(valid)\n",
        "\n",
        "    # target data\n",
        "    y_train = train.Y\n",
        "    y_valid = valid.Y\n",
        "\n",
        "\n",
        "    lin = LinearRegression()\n",
        "    lin.fit(x_train, y_train)\n",
        "    y_pred_valid = lin.predict(x_valid)\n",
        "    LR.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "    knn = KNeighborsRegressor()\n",
        "    knn.fit(x_train, y_train)\n",
        "    y_pred_valid = knn.predict(x_valid)\n",
        "    KNN.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "    dt = DecisionTreeRegressor(random_state=0)\n",
        "    dt.fit(x_train, y_train)\n",
        "    y_pred_valid = dt.predict(x_valid)\n",
        "    DT.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "    bag = BaggingRegressor(DecisionTreeRegressor(), random_state=0)\n",
        "    bag.fit(x_train, y_train)\n",
        "    y_pred_valid = bag.predict(x_valid)\n",
        "    Bag.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "    rf = RandomForestRegressor(random_state=0)\n",
        "    rf.fit(x_train, y_train)\n",
        "    y_pred_valid = rf.predict(x_valid)\n",
        "    RF.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "    et = ExtraTreesRegressor(random_state=0)\n",
        "    et.fit(x_train, y_train)\n",
        "    y_pred_valid = et.predict(x_valid)\n",
        "    ET.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "    grad = GradientBoostingRegressor(random_state=0)\n",
        "    grad.fit(x_train, y_train)\n",
        "    y_pred_valid = grad.predict(x_valid)\n",
        "    GB.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "    ada = AdaBoostRegressor(DecisionTreeRegressor(),random_state=0)\n",
        "    ada.fit(x_train, y_train)\n",
        "    y_pred_valid = ada.predict(x_valid)\n",
        "    AB.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "\n",
        "  # Find out which model gives lowest average MAE\n",
        "  avg_mae = []\n",
        "  models = ['Linear', 'K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Gradient_Boosting', 'Ada_Boost']\n",
        "  for ml_mae in [LR, KNN, DT, Bag, RF, ET, GB, AB]:\n",
        "    avg_mae.append(np.mean(ml_mae))\n",
        "  avg_mae = pd.Series(avg_mae, index = models)\n",
        "  \n",
        "\n",
        "\n",
        "  best_model_name = avg_mae[avg_mae == np.sort(avg_mae)[0]].index[0]\n",
        "  best_model_store.append(best_model_name)\n",
        "\n",
        "ml_model = [lin, knn, dt, bag, rf, et, grad, ada]\n",
        "for data_set in np.arange(0,9):\n",
        "  best_model = ml_model[models.index(best_model_store[data_set])]\n",
        "  best_model_list.append(best_model)\n",
        "\n",
        "best_model_series = pd.Series(best_model_list, index = regression_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vZgpdRMFp6P",
        "outputId": "9535a7e5-17b7-476e-f82b-461a6a75c3b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "caco2_wang                   (ExtraTreeRegressor(random_state=209652396), E...\n",
              "lipophilicity_astrazeneca    (ExtraTreeRegressor(random_state=209652396), E...\n",
              "solubility_aqsoldb           (ExtraTreeRegressor(random_state=209652396), E...\n",
              "ppbr_az                      ([DecisionTreeRegressor(criterion='friedman_ms...\n",
              "vdss_lombardo                (DecisionTreeRegressor(random_state=209652396)...\n",
              "half_life_obach              (DecisionTreeRegressor(random_state=209652396)...\n",
              "clearance_microsome_az       (DecisionTreeRegressor(random_state=209652396)...\n",
              "clearance_hepatocyte_az      (DecisionTreeRegressor(random_state=209652396)...\n",
              "ld50_zhu                     (ExtraTreeRegressor(random_state=209652396), E...\n",
              "dtype: object"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 27 molecular descriptors\n",
        "best_model_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfZi4z70ZL3h",
        "outputId": "c584515e-692b-479c-82ef-3e96573c1962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ExtraTreesRegressor(random_state=0),\n",
              "       ExtraTreesRegressor(random_state=0),\n",
              "       ExtraTreesRegressor(random_state=0),\n",
              "       GradientBoostingRegressor(random_state=0),\n",
              "       AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), random_state=0),\n",
              "       AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), random_state=0),\n",
              "       AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), random_state=0),\n",
              "       AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), random_state=0),\n",
              "       ExtraTreesRegressor(random_state=0)], dtype=object)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 27 molecular descriptors\n",
        "best_model_series.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2W_ks33Xja0"
      },
      "source": [
        "Classification data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3SoufYqXW3K"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
        "\n",
        "from sklearn.metrics import accuracy_score as acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRLGfVDCYb_t"
      },
      "outputs": [],
      "source": [
        "classification_datasets = ['hia_hou', \n",
        "                       'pgp_broccatelli', \n",
        "                       'bioavailability_ma', \n",
        "                       'bbb_martins', \n",
        "                       'cyp2d6_veith', \n",
        "                       'cyp3a4_veith', \n",
        "                       'cyp2c9_veith',\n",
        "                       'cyp2d6_substrate_carbonmangels', \n",
        "                       'cyp3a4_substrate_carbonmangels',\n",
        "                       'cyp2c9_substrate_carbonmangels',\n",
        "                       'herg',\n",
        "                       'ames',\n",
        "                       'dili']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDjINI1EXW0h",
        "outputId": "8e09cf18-7876-4328-8bb9-eed9795a9293"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found local copy...\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2958.09it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2535.83it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2545.62it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2535.49it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2515.19it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2303.29it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2362.11it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2329.64it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2338.57it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2317.69it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2468.75it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2308.79it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2409.52it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2412.68it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2252.16it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2610.74it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2622.17it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2534.20it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2637.40it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2670.19it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2667.80it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:04<00:00, 2196.36it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:04<00:00, 2502.99it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2666.15it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:04<00:00, 2607.07it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2880.35it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2852.04it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2881.49it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2840.50it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2831.84it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2799.48it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2723.59it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2792.74it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2599.70it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2725.29it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2461.44it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2390.54it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2476.56it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2364.08it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2352.34it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2366.58it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2276.44it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2260.91it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2260.93it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2310.31it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2326.03it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2398.30it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2384.55it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2341.53it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2441.35it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2040.89it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2181.65it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2101.55it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2170.45it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2072.22it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4614.79it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4686.47it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4905.96it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4747.43it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4793.85it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 2404.89it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 2275.01it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 2378.13it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 2395.28it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 2463.88it/s]\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "\n",
        "best_Cmodel_list = []\n",
        "best_Cmodel_store = []\n",
        "\n",
        "for clf_data in classification_datasets:\n",
        "  \n",
        "  LR = []\n",
        "  SGD = []\n",
        "  PT = []\n",
        "  PAC = []\n",
        "  LDA = []\n",
        "  Svc = []\n",
        "  KNN = []\n",
        "  NC = []\n",
        "  GNB = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  GB = []\n",
        "  AB = []\n",
        "  LP = []\n",
        "  LS = []\n",
        "\n",
        "  for seed in np.arange(1,6):\n",
        "    benchmark = group.get(clf_data)\n",
        "    name = benchmark['name']\n",
        "\n",
        "    # split the dataset into train_val & test set\n",
        "    train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "    # split the train_val set into train & validation set\n",
        "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'scaffold', seed = seed)\n",
        "\n",
        "      ### I will only use train & valid set to find the best model.\n",
        "      ### And test set will be used as indipendent test set to generalise my best model's performance.\n",
        "\n",
        "    # feature extracting\n",
        "    x_train = molecular_descriptors(train)\n",
        "    x_valid = molecular_descriptors(valid)\n",
        "\n",
        "    # target data\n",
        "    y_train = train.Y\n",
        "    y_valid = valid.Y\n",
        "\n",
        "    # linear_model\n",
        "\n",
        "    log = LogisticRegression(random_state=0)\n",
        "    log.fit(x_train, y_train)\n",
        "    y_pred_valid = log.predict(x_valid)\n",
        "    LR.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    sgd = SGDClassifier(random_state=0)\n",
        "    sgd.fit(x_train, y_train)\n",
        "    y_pred_valid = sgd.predict(x_valid)\n",
        "    SGD.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    pt = Perceptron(random_state=0)\n",
        "    pt.fit(x_train, y_train)\n",
        "    y_pred_valid = pt.predict(x_valid)\n",
        "    PT.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    pac = PassiveAggressiveClassifier(random_state=0)\n",
        "    pac.fit(x_train, y_train)\n",
        "    y_pred_valid = pac.predict(x_valid)\n",
        "    PAC.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    # discriminant_analysis\n",
        "\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "    lda.fit(x_train, y_train)\n",
        "    y_pred_valid = lda.predict(x_valid)\n",
        "    LDA.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    # svm\n",
        "\n",
        "    svc = SVC()\n",
        "    svc.fit(x_train, y_train)\n",
        "    y_pred_valid = svc.predict(x_valid)\n",
        "    Svc.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    # neighbors\n",
        "\n",
        "    knn = KNeighborsClassifier()\n",
        "    knn.fit(x_train, y_train)\n",
        "    y_pred_valid = knn.predict(x_valid)\n",
        "    KNN.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    nc = NearestCentroid()\n",
        "    nc.fit(x_train, y_train)\n",
        "    y_pred_valid = nc.predict(x_valid)\n",
        "    NC.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    # naive_bayes\n",
        "\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(x_train, y_train)\n",
        "    y_pred_valid = gnb.predict(x_valid)\n",
        "    GNB.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    # tree\n",
        "\n",
        "    dt = DecisionTreeClassifier(random_state=0)\n",
        "    dt.fit(x_train, y_train)\n",
        "    y_pred_valid = dt.predict(x_valid)\n",
        "    DT.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    # ensemble\n",
        "\n",
        "    bag = BaggingClassifier(DecisionTreeClassifier(), random_state=0)\n",
        "    bag.fit(x_train, y_train)\n",
        "    y_pred_valid = bag.predict(x_valid)\n",
        "    Bag.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    rf = RandomForestClassifier(random_state=0)\n",
        "    rf.fit(x_train, y_train)\n",
        "    y_pred_valid = rf.predict(x_valid)\n",
        "    RF.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    et = ExtraTreesClassifier(random_state=0)\n",
        "    et.fit(x_train, y_train)\n",
        "    y_pred_valid = et.predict(x_valid)\n",
        "    ET.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    grad = GradientBoostingClassifier(random_state=0)\n",
        "    grad.fit(x_train, y_train)\n",
        "    y_pred_valid = grad.predict(x_valid)\n",
        "    GB.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    ada = AdaBoostClassifier(DecisionTreeClassifier(),random_state=0)\n",
        "    ada.fit(x_train, y_train)\n",
        "    y_pred_valid = ada.predict(x_valid)\n",
        "    AB.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    # semi_supervised\n",
        "\n",
        "    lp = LabelPropagation()\n",
        "    lp.fit(x_train, y_train)\n",
        "    y_pred_valid = lp.predict(x_valid)\n",
        "    LP.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "    ls = LabelSpreading()\n",
        "    ls.fit(x_train, y_train)\n",
        "    y_pred_valid = ls.predict(x_valid)\n",
        "    LS.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "\n",
        "  # Find out which model gives lowest average MAE\n",
        "  avg_acc = []\n",
        "  models = ['Logistic', 'SGD', 'Perceptron', 'Passive_Aggressive', 'Linear_Discriminant_Analysis', 'SVM', \n",
        "            'K_Neighbors', 'Nearest_Centroid', 'Gaussian_NB', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Gradient_Boosting', 'Ada_Boost',\n",
        "            'Label_Propagation', 'Label_Spreading']\n",
        "  for ml_acc in [LR, SGD, PT, PAC, LDA, Svc, KNN, NC, GNB, DT, Bag, RF, ET, GB, AB, LP, LS]:\n",
        "    avg_acc.append(np.mean(ml_acc))\n",
        "  avg_acc = pd.Series(avg_acc, index = models)\n",
        "  \n",
        "\n",
        "\n",
        "  best_Cmodel_name = avg_acc[avg_acc == np.sort(avg_acc)[-1]].index[0]\n",
        "  best_Cmodel_store.append(best_Cmodel_name)\n",
        "\n",
        "best_Cmodel_list = []\n",
        "ml_model = [log, sgd, pt, pac, lda, svc, knn, nc, gnb, dt, bag, rf, et, grad, ada, lp, ls]\n",
        "\n",
        "for data_set in np.arange(0,13):\n",
        "  best_model = ml_model[models.index(best_Cmodel_store[data_set])]\n",
        "  best_Cmodel_list.append(best_model)\n",
        "\n",
        "best_Cmodel_series = pd.Series(best_Cmodel_list, index = classification_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7fbi4BGFxZa",
        "outputId": "af6d632e-22f9-438c-ff11-7fae59f6b598"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "hia_hou                                                LinearDiscriminantAnalysis()\n",
              "pgp_broccatelli                   (DecisionTreeClassifier(max_features='auto', r...\n",
              "bioavailability_ma                                                     Perceptron()\n",
              "bbb_martins                       (DecisionTreeClassifier(max_features='auto', r...\n",
              "cyp2d6_veith                      (DecisionTreeClassifier(max_features='auto', r...\n",
              "cyp3a4_veith                      (DecisionTreeClassifier(max_features='auto', r...\n",
              "cyp2c9_veith                      (DecisionTreeClassifier(max_features='auto', r...\n",
              "cyp2d6_substrate_carbonmangels    (ExtraTreeClassifier(random_state=209652396), ...\n",
              "cyp3a4_substrate_carbonmangels                         LinearDiscriminantAnalysis()\n",
              "cyp2c9_substrate_carbonmangels    (ExtraTreeClassifier(random_state=209652396), ...\n",
              "herg                              (DecisionTreeClassifier(random_state=208755735...\n",
              "ames                              (ExtraTreeClassifier(random_state=209652396), ...\n",
              "dili                                             LogisticRegression(random_state=0)\n",
              "dtype: object"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 27 molecular descriptors\n",
        "best_Cmodel_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orljMv_KFumu",
        "outputId": "0d25ff57-31a0-41fd-bace-06c46ecb3db9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([LinearDiscriminantAnalysis(),\n",
              "       RandomForestClassifier(random_state=0), Perceptron(),\n",
              "       RandomForestClassifier(random_state=0),\n",
              "       RandomForestClassifier(random_state=0),\n",
              "       RandomForestClassifier(random_state=0),\n",
              "       RandomForestClassifier(random_state=0),\n",
              "       ExtraTreesClassifier(random_state=0), LinearDiscriminantAnalysis(),\n",
              "       ExtraTreesClassifier(random_state=0),\n",
              "       BaggingClassifier(base_estimator=DecisionTreeClassifier(), random_state=0),\n",
              "       ExtraTreesClassifier(random_state=0),\n",
              "       LogisticRegression(random_state=0)], dtype=object)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 27 molecular descriptors\n",
        "best_Cmodel_series.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_jN4E99bhZA"
      },
      "source": [
        "# Train on train data \n",
        "# &\n",
        "# Predict for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqPGjawnXWxH",
        "outputId": "88096c9c-36ed-4998-87e7-1fbb132560bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found local copy...\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2294.29it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2636.97it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2291.20it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3001.41it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2563.81it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4777.13it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2659.96it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2264.14it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1839.38it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2663.15it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2819.00it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2725.18it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2972.01it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2738.71it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2284.69it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2059.64it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2223.37it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2122.54it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2367.09it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4599.13it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 2910.19it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5494.50it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2341.41it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2852.28it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2291.84it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3079.87it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2569.84it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4764.97it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2758.04it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2414.32it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1863.78it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:04<00:00, 2569.08it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2867.08it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2778.42it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2951.57it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2914.34it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2570.91it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2209.60it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2437.99it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2285.23it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2582.61it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4929.19it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3149.59it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5562.55it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2359.49it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2914.28it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2285.40it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2724.10it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2545.66it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4871.39it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2819.49it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2452.39it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1873.06it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2697.26it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2840.02it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:04<00:00, 2312.03it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2919.99it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2427.21it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2380.84it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2122.78it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2484.45it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2383.97it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2355.87it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4758.34it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3010.88it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5780.63it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2384.44it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 2997.31it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2221.79it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2980.62it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2544.68it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4756.89it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2743.39it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2399.78it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1878.98it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:04<00:00, 2581.37it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2809.01it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2729.56it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2791.84it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2801.10it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2410.24it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2112.08it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2277.64it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2219.68it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2613.83it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4763.76it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 2908.58it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5672.34it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2182.28it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3031.48it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2229.60it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3054.93it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2502.01it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4699.73it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2714.74it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2306.13it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1876.34it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2643.41it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2752.81it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2749.51it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2834.54it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2922.42it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2609.43it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2275.36it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 1973.55it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2389.70it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2592.97it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4839.61it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3157.87it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5708.50it/s]\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "predictions_list = []\n",
        "\n",
        "for seed in [1, 2, 3, 4, 5]:\n",
        "    predictions = {}\n",
        "\n",
        "    for benchmark in group:\n",
        "        name = benchmark['name']\n",
        "        train_val, test = benchmark['train_val'], benchmark['test']\n",
        "        train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
        "\n",
        "        ## --- train your model --- ##\n",
        "\n",
        "        x_train = molecular_descriptors(train)\n",
        "        x_valid = molecular_descriptors(valid)\n",
        "        x_test = molecular_descriptors(test)\n",
        "\n",
        "        # target column\n",
        "        y_train = train.Y\n",
        "        y_valid = valid.Y\n",
        "        y_test = test.Y\n",
        "\n",
        "        # merging traning and validation set\n",
        "        #x_train_valid = pd.concat([x_train, x_valid])\n",
        "        #y_train_valid = pd.concat([y_train, y_valid], axis=0)\n",
        "\n",
        "        if name in regression_datasets:\n",
        "          model = best_model_series[name]\n",
        "\n",
        "        elif name in classification_datasets:\n",
        "          model = best_Cmodel_series[name]\n",
        "\n",
        "        # fit and predict\n",
        "        model.fit(x_train, y_train)\n",
        "        y_pred_test = model.predict(x_test)\n",
        "        \n",
        "\n",
        "        predictions[name] = y_pred_test\n",
        "    predictions_list.append(predictions)\n",
        "\n",
        "results = group.evaluate_many(predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ3TmbK7uuAB",
        "outputId": "8797575d-285b-4b84-dce3-f274778166ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ames': [0.687, 0.009],\n",
              " 'bbb_martins': [0.77, 0.017],\n",
              " 'bioavailability_ma': [0.504, 0.006],\n",
              " 'caco2_wang': [0.337, 0.011],\n",
              " 'clearance_hepatocyte_az': [0.297, 0.058],\n",
              " 'clearance_microsome_az': [0.325, 0.04],\n",
              " 'cyp2c9_substrate_carbonmangels': [0.291, 0.014],\n",
              " 'cyp2c9_veith': [0.519, 0.006],\n",
              " 'cyp2d6_substrate_carbonmangels': [0.41, 0.018],\n",
              " 'cyp2d6_veith': [0.292, 0.008],\n",
              " 'cyp3a4_substrate_carbonmangels': [0.625, 0.014],\n",
              " 'cyp3a4_veith': [0.618, 0.006],\n",
              " 'dili': [0.823, 0.026],\n",
              " 'half_life_obach': [0.294, 0.041],\n",
              " 'herg': [0.674, 0.018],\n",
              " 'hia_hou': [0.783, 0.014],\n",
              " 'ld50_zhu': [0.673, 0.002],\n",
              " 'lipophilicity_astrazeneca': [0.727, 0.007],\n",
              " 'pgp_broccatelli': [0.807, 0.019],\n",
              " 'ppbr_az': [8.816, 0.08],\n",
              " 'solubility_aqsoldb': [0.897, 0.02],\n",
              " 'vdss_lombardo': [0.465, 0.039]}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 27 molecular descriptors (train on train set)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d2v3v7f5CwB"
      },
      "outputs": [],
      "source": [
        "# Rank of models using 27 molecular descriptors (train on train set)\n",
        "\n",
        "# DataSet                       TDC LeaderBoard Rank\n",
        "\n",
        "# ames                              XXX\n",
        "# bbb_martins                       XXX\n",
        "# bioavailability_ma                XXX\n",
        "# caco2_wang                        1st\n",
        "# clearance_hepatocyte_az           6th\n",
        "# clearance_microsome_az            9th\n",
        "# cyp2c9_substrate_carbonmangels    XXX\n",
        "# cyp2c9_veith                      XXX\n",
        "# cyp2d6_substrate_carbonmangels    XXX\n",
        "# cyp2d6_veith                      XXX\n",
        "# cyp3a4_substrate_carbonmangels    5th\n",
        "# cyp3a4_veith                      XXX\n",
        "# dili                              9th\n",
        "# half_life_obach                   3rd\n",
        "# herg                              XXX\n",
        "# hia_hou                           XXX\n",
        "# ld50_zhu                          5th\n",
        "# lipophilicity_astrazeneca         8th\n",
        "# pgp_broccatelli                   XXX\n",
        "# ppbr_az                           1st\n",
        "# solubility_aqsoldb                3rd\n",
        "# vdss_lombardo                     6th"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ADMET prediction using Descriptors.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
