{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADMET Properties Prediction Using Descriptors.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "jKEt396_iv5U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okF3BVjDh5OG"
      },
      "outputs": [],
      "source": [
        "pip install PyTDC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rdkit-pypi"
      ],
      "metadata": {
        "id": "4qRNnuOQiNK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Lipinski"
      ],
      "metadata": {
        "id": "DorC_z3EiNIL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating global features extractor function"
      ],
      "metadata": {
        "id": "Y6kKvNtRiWGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def molecular_descriptors(table):\n",
        "\n",
        "  descriptors = pd.DataFrame()\n",
        "\n",
        "  mol = [Chem.MolFromSmiles(drug) for drug in table.Drug]\n",
        "\n",
        "  # Exact molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.ExactMolWt(i) for i in mol])\n",
        "  descriptors['Exact_MW'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan1\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan1(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan1'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan2\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan2(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan2'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan3\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan3(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan3'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule ignoring hydrogens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.HeavyAtomMolWt(i) for i in mol])\n",
        "  descriptors['HeavyAtomMolWt'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MinAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinPartialCharge(i) for i in mol])\n",
        "  descriptors['MinPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolWt(i) for i in mol])\n",
        "  descriptors['MolWt'] = Nilavo[0]\n",
        "\n",
        "  # Number of radical electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumRadicalElectrons(i) for i in mol])\n",
        "  descriptors['NumRadicalElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Number of valence electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumValenceElectrons(i) for i in mol])\n",
        "  descriptors['NumValenceElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Log of partition coefficient\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolLogP(i) for i in mol])\n",
        "  descriptors['Partition_Coefficient'] = Nilavo[0]\n",
        "\n",
        "\n",
        "  ### Lipinski Descriptors ###\n",
        "  # Fraction of C atoms that are SP3 hybridized\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.FractionCSP3(i) for i in mol])\n",
        "  descriptors['FractionCSP3'] = Nilavo[0]\n",
        "\n",
        "  # Number of heavy atoms a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.HeavyAtomCount(i) for i in mol])\n",
        "  descriptors['Heavy_atoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of NHs or OHs\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NHOHCount(i) for i in mol])\n",
        "  descriptors['NHs/OHs'] = Nilavo[0]\n",
        "\n",
        "  # Number of Nitrogens and Oxygens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NOCount(i) for i in mol])\n",
        "  descriptors['N&O'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticRings(i) for i in mol])\n",
        "  descriptors['Aliphatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Nmber of aromatic carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticRings(i) for i in mol])\n",
        "  descriptors['Aromatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Acceptors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHAcceptors(i) for i in mol])\n",
        "  descriptors['HAcceptors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Donors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHDonors(i) for i in mol])\n",
        "  descriptors['HDonors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Heteroatoms\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHeteroatoms(i) for i in mol])\n",
        "  descriptors['Heteroatoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of Rotatable Bonds\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumRotatableBonds(i) for i in mol])\n",
        "  descriptors['Rotatable_Bonds'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedCarbocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedHeterocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedRings(i) for i in mol])\n",
        "  descriptors['Saturated_Rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.RingCount(i) for i in mol])\n",
        "  descriptors['Rings'] = Nilavo[0]\n",
        "\n",
        "  return descriptors"
      ],
      "metadata": {
        "id": "ZYdv6Q-wiNFR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Problems"
      ],
      "metadata": {
        "id": "9cWmU7Xwi3-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ],
      "metadata": {
        "id": "rj6FJ81CiNCq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_datasets = ['caco2_wang', \n",
        "                       'lipophilicity_astrazeneca', \n",
        "                       'solubility_aqsoldb', \n",
        "                       'ppbr_az', \n",
        "                       'vdss_lombardo', \n",
        "                       'half_life_obach', \n",
        "                       'clearance_microsome_az',\n",
        "                       'clearance_hepatocyte_az', \n",
        "                       'ld50_zhu'\n",
        "                      ]"
      ],
      "metadata": {
        "id": "K6FCMuNAkYUT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Search best ML models"
      ],
      "metadata": {
        "id": "_M7NOMK-i_U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "best_model_list = []\n",
        "\n",
        "for reg_data in regression_datasets:\n",
        "  LR = []\n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  GB = []\n",
        "  AB = []\n",
        "\n",
        "  benchmark = group.get(reg_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "  train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = 1)\n",
        "\n",
        "  # feature extracting\n",
        "  x_train = molecular_descriptors(train)\n",
        "  x_valid = molecular_descriptors(valid)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train = np.nan_to_num(x_train, nan=0, posinf=0)\n",
        "  x_valid = np.nan_to_num(x_valid, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train = train.Y\n",
        "  y_valid = valid.Y\n",
        "\n",
        "  ### USE ONLY TRAINING AND VALIDATION SET TO SELECT MODEL ###\n",
        "\n",
        "  lin = LinearRegression()\n",
        "  lin.fit(x_train, y_train)\n",
        "  y_pred_valid = lin.predict(x_valid)\n",
        "  LR.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  knn = KNeighborsRegressor()\n",
        "  knn.fit(x_train, y_train)\n",
        "  y_pred_valid = knn.predict(x_valid)\n",
        "  KNN.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  dt = DecisionTreeRegressor(random_state=0)\n",
        "  dt.fit(x_train, y_train)\n",
        "  y_pred_valid = dt.predict(x_valid)\n",
        "  DT.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  bag = BaggingRegressor(DecisionTreeRegressor(), random_state=0)\n",
        "  bag.fit(x_train, y_train)\n",
        "  y_pred_valid = bag.predict(x_valid)\n",
        "  Bag.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  rf = RandomForestRegressor(random_state=0)\n",
        "  rf.fit(x_train, y_train)\n",
        "  y_pred_valid = rf.predict(x_valid)\n",
        "  RF.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  et = ExtraTreesRegressor(random_state=0)\n",
        "  et.fit(x_train, y_train)\n",
        "  y_pred_valid = et.predict(x_valid)\n",
        "  ET.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  grad = GradientBoostingRegressor(random_state=0)\n",
        "  grad.fit(x_train, y_train)\n",
        "  y_pred_valid = grad.predict(x_valid)\n",
        "  GB.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  ada = AdaBoostRegressor(DecisionTreeRegressor(),random_state=0)\n",
        "  ada.fit(x_train, y_train)\n",
        "  y_pred_valid = ada.predict(x_valid)\n",
        "  AB.append(mae(y_valid, y_pred_valid))\n",
        "\n",
        "  # Find out which model gives lowest MAE\n",
        "  m = []\n",
        "  models = ['Linear', 'K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Gradient_Boosting', 'Ada_Boost']\n",
        "  for ml_mae in [LR, KNN, DT, Bag, RF, ET, GB, AB]:\n",
        "    m.append(ml_mae)\n",
        "  m = pd.Series(m, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  mae_tune = []\n",
        "  best_model_store = []\n",
        "\n",
        "  for low_mae in [0, 1, 2]:\n",
        "      best_model_name = m[m == np.sort(m)[low_mae][0]].index[0]\n",
        "\n",
        "      ml_model = [lin, knn, dt, bag, rf, et, grad, ada]\n",
        "      best_model = ml_model[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Linear':\n",
        "        best_model = LinearRegression()\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(LR[0])\n",
        "\n",
        "      elif best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeRegressor(random_state=0)\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsRegressor(n_neighbors = best_param)\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        mae_tune.append(mae(y_valid, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingRegressor(DecisionTreeRegressor(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestRegressor(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesRegressor(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        mae_tune.append(mae(y_valid, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Gradient_Boosting':\n",
        "          best_model = GradientBoostingRegressor(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        mae_tune.append(mae(y_valid, y_p))\n",
        "\n",
        "  mae_tune_series = pd.Series(mae_tune, index = best_model_store)\n",
        "\n",
        "  best_model = mae_tune_series[mae_tune_series == min(mae_tune_series)].index[0]\n",
        "  best_model_list.append(best_model)\n",
        "\n",
        "best_model_series = pd.Series(best_model_list, index = regression_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txds884-i8bN",
        "outputId": "e0109b36-84a1-43f7-ac11-08281b512a09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Benchmark Group...\n",
            "100%|██████████| 1.47M/1.47M [00:00<00:00, 20.4MiB/s]\n",
            "Extracting zip file...\n",
            "Done!\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 831.26it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:03<00:00, 858.79it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4923.60it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2491.33it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1956.94it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2338.02it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2443.57it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2359.12it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5660.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_series"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvTJPi99kfk-",
        "outputId": "d733a1f6-a4c0-42f8-e658-9a09388fd75d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "caco2_wang                   AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "lipophilicity_astrazeneca    AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "solubility_aqsoldb           AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "ppbr_az                      GradientBoostingRegressor(learning_rate=0.005,...\n",
              "vdss_lombardo                AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "half_life_obach              AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "clearance_microsome_az       AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "clearance_hepatocyte_az      ExtraTreesRegressor(n_estimators=500, random_s...\n",
              "ld50_zhu                     ExtraTreesRegressor(n_estimators=350, random_s...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9YHs2XAkgJx",
        "outputId": "a7dd3578-f426-459f-dbb0-fc8c8f2af745"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
              "                   n_estimators=500, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.3,\n",
              "                   n_estimators=500, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
              "                   n_estimators=450, random_state=0),\n",
              " GradientBoostingRegressor(learning_rate=0.005, n_estimators=500, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.005,\n",
              "                   n_estimators=200, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.08,\n",
              "                   n_estimators=350, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.3,\n",
              "                   n_estimators=350, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=500, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=350, random_state=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Problems"
      ],
      "metadata": {
        "id": "o0wMfKcpkrZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score as acc"
      ],
      "metadata": {
        "id": "0tFKCIQikiTd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_datasets = ['hia_hou', \n",
        "                       'pgp_broccatelli', \n",
        "                       'bioavailability_ma', \n",
        "                       'bbb_martins', \n",
        "                       'cyp2d6_veith', \n",
        "                       'cyp3a4_veith', \n",
        "                       'cyp2c9_veith',\n",
        "                       'cyp2d6_substrate_carbonmangels', \n",
        "                       'cyp3a4_substrate_carbonmangels',\n",
        "                       'cyp2c9_substrate_carbonmangels',\n",
        "                       'herg',\n",
        "                       'ames',\n",
        "                       'dili'\n",
        "                       ]"
      ],
      "metadata": {
        "id": "bu-3Vhe2lBKR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Search best ML models"
      ],
      "metadata": {
        "id": "h9SZryP2k3IC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "best_Cmodel_list = []\n",
        "\n",
        "for clf_data in classification_datasets:\n",
        "  \n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  AB = []\n",
        "  XG = []\n",
        "\n",
        "  benchmark = group.get(clf_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "  train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = 1)\n",
        "\n",
        "  # feature extracting\n",
        "  x_train = molecular_descriptors(train)\n",
        "  x_valid = molecular_descriptors(valid)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train = np.nan_to_num(x_train, nan=0, posinf=0)\n",
        "  x_valid = np.nan_to_num(x_valid, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train = train.Y\n",
        "  y_valid = valid.Y\n",
        "\n",
        "  ### USE ONLY TRAINING AND VALIDATION SET TO SELECT MODEL ###\n",
        "\n",
        "  # neighbors\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn.fit(x_train, y_train)\n",
        "  y_pred_valid = knn.predict(x_valid)\n",
        "  KNN.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  # tree\n",
        "  dt = DecisionTreeClassifier(random_state=0)\n",
        "  dt.fit(x_train, y_train)\n",
        "  y_pred_valid = dt.predict(x_valid)\n",
        "  DT.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  # ensemble\n",
        "  bag = BaggingClassifier(DecisionTreeClassifier(), random_state=0)\n",
        "  bag.fit(x_train, y_train)\n",
        "  y_pred_valid = bag.predict(x_valid)\n",
        "  Bag.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  rf = RandomForestClassifier(random_state=0)\n",
        "  rf.fit(x_train, y_train)\n",
        "  y_pred_valid = rf.predict(x_valid)\n",
        "  RF.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  et = ExtraTreesClassifier(random_state=0)\n",
        "  et.fit(x_train, y_train)\n",
        "  y_pred_valid = et.predict(x_valid)\n",
        "  ET.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  ada = AdaBoostClassifier(DecisionTreeClassifier(),random_state=0)\n",
        "  ada.fit(x_train, y_train)\n",
        "  y_pred_valid = ada.predict(x_valid)\n",
        "  AB.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  xg = XGBClassifier(random_state=0)\n",
        "  xg.fit(x_train, y_train)\n",
        "  y_pred_valid = xg.predict(x_valid)\n",
        "  XG.append(acc(y_valid, y_pred_valid))\n",
        "\n",
        "  # Find out which model gives highest accuracy\n",
        "  a = []\n",
        "  models = ['K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Ada_Boost', 'XG_Boost']\n",
        "\n",
        "  for ml_acc in [KNN, DT, Bag, RF, ET, AB, XG]:\n",
        "    a.append(ml_acc)\n",
        "  a = pd.Series(a, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  acc_tune = []\n",
        "  best_Cmodel_store = []\n",
        "\n",
        "  for high_acc in [-1, -2]:\n",
        "      best_model_name = a[a == np.sort(a)[high_acc][0]].index[0]\n",
        "\n",
        "      ml_Cmodel = [knn, dt, bag, rf, et, ada, xg]\n",
        "      best_model = ml_Cmodel[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeClassifier(random_state=0)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "        acc_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsClassifier(n_neighbors = best_param)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        acc_tune.append(acc(y_valid, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestClassifier(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesClassifier(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        acc_tune.append(acc(y_valid, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train, y_train)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Ada_Boost':\n",
        "          best_model = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = XGBClassifier(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "          \n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_valid)\n",
        "        acc_tune.append(acc(y_valid, y_p))\n",
        "\n",
        "  acc_tune_series = pd.Series(acc_tune, index = best_Cmodel_store)\n",
        "\n",
        "  best_Cmodel = acc_tune_series[acc_tune_series == max(acc_tune_series)].index[0]\n",
        "  best_Cmodel_list.append(best_model)\n",
        "\n",
        "best_Cmodel_series = pd.Series(best_Cmodel_list, index = classification_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfaUohSak0Zf",
        "outputId": "45764b66-ba04-4f95-a490-97bf0dbfe253"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3279.83it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2633.32it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3114.05it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2851.14it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2761.57it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2961.92it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2886.68it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 3088.80it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2934.64it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2864.14it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2752.37it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4939.58it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3314.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_Cmodel_series"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSDzYjuElKr6",
        "outputId": "18680c5e-5de4-456b-c0bb-3d535e3bb7b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "hia_hou                           BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "pgp_broccatelli                   ExtraTreesClassifier(n_estimators=500, random_...\n",
              "bioavailability_ma                RandomForestClassifier(n_estimators=400, rando...\n",
              "bbb_martins                       BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "cyp2d6_veith                      ExtraTreesClassifier(n_estimators=250, random_...\n",
              "cyp3a4_veith                                        XGBClassifier(n_estimators=400)\n",
              "cyp2c9_veith                      BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "cyp2d6_substrate_carbonmangels    BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "cyp3a4_substrate_carbonmangels    XGBClassifier(learning_rate=0.005, n_estimator...\n",
              "cyp2c9_substrate_carbonmangels    BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "herg                              BaggingClassifier(base_estimator=DecisionTreeC...\n",
              "ames                              ExtraTreesClassifier(n_estimators=500, random_...\n",
              "dili                                            KNeighborsClassifier(n_neighbors=4)\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_Cmodel_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlk04wyNlLH2",
        "outputId": "3834b9ba-b514-4789-ec50-44204e932d0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=200,\n",
              "                   random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=500, random_state=0),\n",
              " RandomForestClassifier(n_estimators=400, random_state=0),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100,\n",
              "                   random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=250, random_state=0),\n",
              " XGBClassifier(n_estimators=400),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=350,\n",
              "                   random_state=0),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=250,\n",
              "                   random_state=0),\n",
              " XGBClassifier(learning_rate=0.005, n_estimators=150),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500,\n",
              "                   random_state=0),\n",
              " BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=150,\n",
              "                   random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=500, random_state=0),\n",
              " KNeighborsClassifier(n_neighbors=4)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate performence of my method"
      ],
      "metadata": {
        "id": "zhdPIfpDlRlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TEST ON INDIPENDENT TEST SET (which was not used in model selection or model training)\n",
        "\n",
        "For robust measurement of model performance, I did five independent runs of the model to calculate average performance and standard deviation."
      ],
      "metadata": {
        "id": "-MhTvlQniaIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "predictions_list = []\n",
        "\n",
        "for seed in [1, 2, 3, 4, 5]:\n",
        "  predictions = {}\n",
        "\n",
        "  for benchmark in group:\n",
        "    name = benchmark['name']\n",
        "    train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "    # split the train_val set into train & validation set\n",
        "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'scaffold', seed = seed)\n",
        "\n",
        "    # extract features from molecule SMILES string\n",
        "    x_train = molecular_descriptors(train)\n",
        "    x_valid = molecular_descriptors(valid)\n",
        "    x_test = molecular_descriptors(test)\n",
        "\n",
        "    # target column\n",
        "    y_train = train.Y\n",
        "    y_valid = valid.Y\n",
        "    y_test = test.Y\n",
        "\n",
        "    # merging traning and validation set\n",
        "    x_train_val = pd.concat([x_train, x_valid])\n",
        "    y_train_val = pd.concat([y_train, y_valid], axis=0)\n",
        "\n",
        "    # Replace NaN values with 0\n",
        "    x_train_val = np.nan_to_num(x_train_val, nan=0, posinf=0)\n",
        "    x_test = np.nan_to_num(x_test, nan=0, posinf=0)\n",
        "\n",
        "    # take appropriate model for different datasets\n",
        "    if name in regression_datasets:\n",
        "      model = best_model_series[name]\n",
        "    elif name in classification_datasets:\n",
        "      model = best_Cmodel_series[name]\n",
        "\n",
        "    # train model on training and validation set\n",
        "    # and\n",
        "    # test on test set \n",
        "    model.fit(x_train_val, y_train_val)\n",
        "    y_pred_test = model.predict(x_test)\n",
        "\n",
        "    predictions[name] = y_pred_test\n",
        "\n",
        "  predictions_list.append(predictions)\n",
        "\n",
        "results = group.evaluate_many(predictions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux6LZdp3lSBD",
        "outputId": "7e896002-ba80-4369-fc1d-0c49107c5096"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2404.57it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3207.54it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2611.53it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3091.75it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2620.86it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 5062.16it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2869.19it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2465.95it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1969.57it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2741.89it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2944.55it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2843.21it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 3036.84it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2945.96it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2986.25it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2330.94it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2450.48it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2350.81it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2678.09it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4824.54it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3315.50it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5584.57it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2456.14it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3203.85it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2505.38it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2865.59it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2598.68it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 5066.35it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2916.34it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2456.37it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1775.39it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2785.53it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2996.88it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2830.33it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 3068.42it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2972.40it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2998.35it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2209.15it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2553.54it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2383.48it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2583.11it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4852.24it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3312.85it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5712.02it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2451.76it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3243.87it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2609.07it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3147.03it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2565.09it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 5060.70it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2853.26it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2498.44it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 2000.20it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2738.64it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2962.03it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2825.44it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 3078.41it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 3028.95it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2975.02it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2284.44it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2471.63it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2441.81it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2707.25it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4836.89it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3280.86it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5657.85it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2523.61it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3113.53it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2482.62it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2965.22it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2603.12it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 5066.22it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2799.00it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2496.06it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 2009.78it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2743.69it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2960.07it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2802.69it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2964.87it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2945.20it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2904.26it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2275.20it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2476.85it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2369.74it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2551.01it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4879.96it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3237.00it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5625.48it/s]\n",
            "--- caco2_wang ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2434.73it/s]\n",
            "--- hia_hou ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3185.70it/s]\n",
            "--- pgp_broccatelli ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2538.81it/s]\n",
            "--- bioavailability_ma ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3033.63it/s]\n",
            "--- lipophilicity_astrazeneca ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2567.98it/s]\n",
            "--- solubility_aqsoldb ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 5038.83it/s]\n",
            "--- bbb_martins ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2875.90it/s]\n",
            "--- ppbr_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 2470.43it/s]\n",
            "--- vdss_lombardo ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 904/904 [00:00<00:00, 1994.81it/s]\n",
            "--- cyp2d6_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2767.57it/s]\n",
            "--- cyp3a4_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9861/9861 [00:03<00:00, 2972.85it/s]\n",
            "--- cyp2c9_veith ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 9673/9673 [00:03<00:00, 2807.47it/s]\n",
            "--- cyp2d6_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2910.51it/s]\n",
            "--- cyp3a4_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 535/535 [00:00<00:00, 2826.06it/s]\n",
            "--- cyp2c9_substrate_carbonmangels ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 534/534 [00:00<00:00, 2823.30it/s]\n",
            "--- half_life_obach ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 532/532 [00:00<00:00, 2262.17it/s]\n",
            "--- clearance_microsome_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 881/881 [00:00<00:00, 2410.11it/s]\n",
            "--- clearance_hepatocyte_az ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 970/970 [00:00<00:00, 2480.83it/s]\n",
            "--- herg ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 523/523 [00:00<00:00, 2604.37it/s]\n",
            "--- ames ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5821/5821 [00:01<00:00, 4839.42it/s]\n",
            "--- dili ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 379/379 [00:00<00:00, 3157.34it/s]\n",
            "--- ld50_zhu ---\n",
            "generating training, validation splits...\n",
            "100%|██████████| 5907/5907 [00:01<00:00, 5674.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRQk3r-Rk_jk",
        "outputId": "a95e5916-f1c1-412f-9635-0ab3012219cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ames': [0.716, 0.0],\n",
              " 'bbb_martins': [0.811, 0.013],\n",
              " 'bioavailability_ma': [0.523, 0.011],\n",
              " 'caco2_wang': [0.321, 0.005],\n",
              " 'clearance_hepatocyte_az': [0.44, 0.003],\n",
              " 'clearance_microsome_az': [0.518, 0.005],\n",
              " 'cyp2c9_substrate_carbonmangels': [0.281, 0.0],\n",
              " 'cyp2c9_veith': [0.556, 0.0],\n",
              " 'cyp2d6_substrate_carbonmangels': [0.478, 0.018],\n",
              " 'cyp2d6_veith': [0.358, 0.0],\n",
              " 'cyp3a4_substrate_carbonmangels': [0.605, 0.0],\n",
              " 'cyp3a4_veith': [0.654, 0.0],\n",
              " 'dili': [0.7, 0.0],\n",
              " 'half_life_obach': [0.438, 0.011],\n",
              " 'herg': [0.715, 0.011],\n",
              " 'hia_hou': [0.818, 0.01],\n",
              " 'ld50_zhu': [0.636, 0.001],\n",
              " 'lipophilicity_astrazeneca': [0.617, 0.003],\n",
              " 'pgp_broccatelli': [0.818, 0.0],\n",
              " 'ppbr_az': [9.185, 0.0],\n",
              " 'solubility_aqsoldb': [0.828, 0.002],\n",
              " 'vdss_lombardo': [0.627, 0.01]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Regression ###\n",
        "\n",
        "#{'caco2_wang': [0.321, 0.005],                       (2) \n",
        "# 'lipophilicity_astrazeneca': [0.617, 0.003],        (8) \n",
        "# 'solubility_aqsoldb': [0.828, 0.002]                (4) \n",
        "# 'half_life_obach': [0.438, 0.011],                  (1) \n",
        "# 'ppbr_az': [9.185, 0.0],                            (2) \n",
        "# 'vdss_lombardo': [0.627, 0.01]                      (1) \n",
        "# 'clearance_hepatocyte_az': [0.44, 0.003],           (1) \n",
        "# 'clearance_microsome_az': [0.518, 0.005],           (8) \n",
        "# 'ld50_zhu': [0.636, 0.001]}                         (4) \n",
        "\n",
        "\n",
        "### Classification ###\n",
        "\n",
        "#{'bbb_martins': [0.811, 0.013],                      (10) \n",
        "# 'bioavailability_ma': [0.523, 0.011],               (-) \n",
        "# 'cyp2d6_veith': [0.358, 0.0],                       (-) \n",
        "# 'hia_hou': [0.818, 0.01],                           (9) \n",
        "# 'pgp_broccatelli': [0.818, 0.0]                     (-) \n",
        "# 'cyp2c9_substrate_carbonmangels': [0.281, 0.0],     (-) \n",
        "# 'cyp2d6_substrate_carbonmangels': [0.478, 0.018],   (-) \n",
        "# 'cyp3a4_substrate_carbonmangels': [0.605, 0.0],     (7) \n",
        "# 'cyp3a4_veith': [0.654, 0.0]                        (-) \n",
        "# 'ames': [0.716, 0.0],                               (-) \n",
        "# 'dili': [0.7, 0.0]                                  (-) \n",
        "# 'herg': [0.715, 0.011]                              (-) \n",
        "# 'cyp2c9_veith': [0.556, 0.0]}                       (-) "
      ],
      "metadata": {
        "id": "CP3qDHbDPyFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
