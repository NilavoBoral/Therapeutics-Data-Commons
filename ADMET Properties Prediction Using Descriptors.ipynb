{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "4saWzc4OoBXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5vPm4Fx2G90"
      },
      "outputs": [],
      "source": [
        "pip install PyTDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7rqvB1y2ul3"
      },
      "outputs": [],
      "source": [
        "pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ynGGpO8c2nVd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Lipinski"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating feature extractor function"
      ],
      "metadata": {
        "id": "HexA92ZXaIoF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8jS9rB2f23KB"
      },
      "outputs": [],
      "source": [
        "def molecular_descriptors(table):\n",
        "\n",
        "  descriptors = pd.DataFrame()\n",
        "\n",
        "  mol = [Chem.MolFromSmiles(drug) for drug in table.Drug]\n",
        "\n",
        "  # Exact molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.ExactMolWt(i) for i in mol])\n",
        "  descriptors['Exact_MW'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan1\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan1(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan1'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan2\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan2(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan2'] = Nilavo[0]\n",
        "\n",
        "  # FpDensityMorgan3\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.FpDensityMorgan3(i) for i in mol])\n",
        "  descriptors['FpDensityMorgan3'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule ignoring hydrogens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.HeavyAtomMolWt(i) for i in mol])\n",
        "  descriptors['HeavyAtomMolWt'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MaxPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MaxPartialCharge(i) for i in mol])\n",
        "  descriptors['MaxPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinAbsPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinAbsPartialCharge(i) for i in mol])\n",
        "  descriptors['MinAbsPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  ###\n",
        "  ### MinPartialCharge ###\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MinPartialCharge(i) for i in mol])\n",
        "  descriptors['MinPartialCharge'] = Nilavo[0]\n",
        "\n",
        "  # Average molecular weight of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolWt(i) for i in mol])\n",
        "  descriptors['MolWt'] = Nilavo[0]\n",
        "\n",
        "  # Number of radical electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumRadicalElectrons(i) for i in mol])\n",
        "  descriptors['NumRadicalElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Number of valence electrons of the molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.NumValenceElectrons(i) for i in mol])\n",
        "  descriptors['NumValenceElectrons'] = Nilavo[0]\n",
        "\n",
        "  # Log of partition coefficient\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Descriptors.MolLogP(i) for i in mol])\n",
        "  descriptors['Partition_Coefficient'] = Nilavo[0]\n",
        "\n",
        "\n",
        "  ### Lipinski Descriptors ###\n",
        "  # Fraction of C atoms that are SP3 hybridized\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.FractionCSP3(i) for i in mol])\n",
        "  descriptors['FractionCSP3'] = Nilavo[0]\n",
        "\n",
        "  # Number of heavy atoms a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.HeavyAtomCount(i) for i in mol])\n",
        "  descriptors['Heavy_atoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of NHs or OHs\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NHOHCount(i) for i in mol])\n",
        "  descriptors['NHs/OHs'] = Nilavo[0]\n",
        "\n",
        "  # Number of Nitrogens and Oxygens\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NOCount(i) for i in mol])\n",
        "  descriptors['N&O'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aliphatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aliphatic (containing at least one non-aromatic bond) rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAliphaticRings(i) for i in mol])\n",
        "  descriptors['Aliphatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Nmber of aromatic carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticCarbocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticHeterocycles(i) for i in mol])\n",
        "  descriptors['Aromatic_heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of aromatic rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumAromaticRings(i) for i in mol])\n",
        "  descriptors['Aromatic_rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Acceptors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHAcceptors(i) for i in mol])\n",
        "  descriptors['HAcceptors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Hydrogen Bond Donors\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHDonors(i) for i in mol])\n",
        "  descriptors['HDonors'] = Nilavo[0]\n",
        "\n",
        "  # Number of Heteroatoms\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumHeteroatoms(i) for i in mol])\n",
        "  descriptors['Heteroatoms'] = Nilavo[0]\n",
        "\n",
        "  # Number of Rotatable Bonds\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumRotatableBonds(i) for i in mol])\n",
        "  descriptors['Rotatable_Bonds'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated carbocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedCarbocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Carbocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated heterocycles for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedHeterocycles(i) for i in mol])\n",
        "  descriptors['Saturated_Heterocycles'] = Nilavo[0]\n",
        "\n",
        "  # Number of saturated rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.NumSaturatedRings(i) for i in mol])\n",
        "  descriptors['Saturated_Rings'] = Nilavo[0]\n",
        "\n",
        "  # Number of rings for a molecule\n",
        "  Nilavo = []\n",
        "  Nilavo.append([Lipinski.RingCount(i) for i in mol])\n",
        "  descriptors['Rings'] = Nilavo[0]\n",
        "\n",
        "  return descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Problems"
      ],
      "metadata": {
        "id": "pkrZuqqoDyWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "AZvpr_ak6HxH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Search best ML models"
      ],
      "metadata": {
        "id": "_JDBn_FDaCpQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjQDGWuW18MM",
        "outputId": "a98a82e6-a50f-47e2-f975-51237ba1ab03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n"
          ]
        }
      ],
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "best_model_list = []\n",
        "\n",
        "regression_datasets = ['caco2_wang', \n",
        "                       'lipophilicity_astrazeneca', \n",
        "                       'solubility_aqsoldb', \n",
        "                       #'ppbr_az', \n",
        "                       #'vdss_lombardo', \n",
        "                       #'half_life_obach', \n",
        "                       #'clearance_microsome_az',\n",
        "                       #'clearance_hepatocyte_az', \n",
        "                       #'ld50_zhu'\n",
        "                      ]\n",
        "\n",
        "for reg_data in regression_datasets:\n",
        "  LR = []\n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  GB = []\n",
        "  AB = []\n",
        "\n",
        "  #for seed in np.arange(1,6):\n",
        "  benchmark = group.get(reg_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "  # feature extracting\n",
        "  x_train_val = molecular_descriptors(train_val)\n",
        "  x_test = molecular_descriptors(test)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train_val = np.nan_to_num(x_train_val, nan=0, posinf=0)\n",
        "  x_test = np.nan_to_num(x_test, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train_val = train_val.Y\n",
        "  y_test = test.Y\n",
        "\n",
        "  #mms = MinMaxScaler()\n",
        "  #x_train_val = mms.fit_transform(x_train_val)\n",
        "  #x_test = mms.transform(x_test)\n",
        "\n",
        "  lin = LinearRegression()\n",
        "  lin.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = lin.predict(x_test)\n",
        "  LR.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  knn = KNeighborsRegressor()\n",
        "  knn.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = knn.predict(x_test)\n",
        "  KNN.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  dt = DecisionTreeRegressor(random_state=0)\n",
        "  dt.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = dt.predict(x_test)\n",
        "  DT.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  bag = BaggingRegressor(DecisionTreeRegressor(), random_state=0)\n",
        "  bag.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = bag.predict(x_test)\n",
        "  Bag.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  rf = RandomForestRegressor(random_state=0)\n",
        "  rf.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = rf.predict(x_test)\n",
        "  RF.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  et = ExtraTreesRegressor(random_state=0)\n",
        "  et.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = et.predict(x_test)\n",
        "  ET.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  grad = GradientBoostingRegressor(random_state=0)\n",
        "  grad.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = grad.predict(x_test)\n",
        "  GB.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  ada = AdaBoostRegressor(DecisionTreeRegressor(),random_state=0)\n",
        "  ada.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = ada.predict(x_test)\n",
        "  AB.append(mae(y_test, y_pred_test))\n",
        "\n",
        "  # Find out which model gives lowest MAE\n",
        "  m = []\n",
        "  models = ['Linear', 'K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Gradient_Boosting', 'Ada_Boost']\n",
        "  for ml_mae in [LR, KNN, DT, Bag, RF, ET, GB, AB]:\n",
        "    m.append(ml_mae)\n",
        "  m = pd.Series(m, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  mae_tune = []\n",
        "  best_model_store = []\n",
        "\n",
        "  for low_mae in [0, 1, 2]:\n",
        "      best_model_name = m[m == np.sort(m)[low_mae][0]].index[0]\n",
        "\n",
        "      ml_model = [lin, knn, dt, bag, rf, et, grad, ada]\n",
        "      best_model = ml_model[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Linear':\n",
        "        best_model = LinearRegression()\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(LR[0])\n",
        "\n",
        "      elif best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeRegressor(random_state=0)\n",
        "        best_model_store.append(best_model)\n",
        "        mae_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsRegressor(n_neighbors = best_param)\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        mae_tune.append(mae(y_test, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingRegressor(DecisionTreeRegressor(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestRegressor(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesRegressor(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        mae_tune.append(mae(y_test, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Gradient_Boosting':\n",
        "          best_model = GradientBoostingRegressor(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = AdaBoostRegressor(DecisionTreeRegressor(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "\n",
        "        best_model_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        mae_tune.append(mae(y_test, y_p))\n",
        "\n",
        "  mae_tune_series = pd.Series(mae_tune, index = best_model_store)\n",
        "\n",
        "  best_model = mae_tune_series[mae_tune_series == min(mae_tune_series)].index[0]\n",
        "  best_model_list.append(best_model)\n",
        "\n",
        "best_model_series = pd.Series(best_model_list, index = regression_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_series"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECUzQTPEqWhI",
        "outputId": "2d27529b-c94d-4820-dd58-e01a70f8a0db"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "caco2_wang                   ExtraTreesRegressor(n_estimators=300, random_s...\n",
              "lipophilicity_astrazeneca    AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
              "solubility_aqsoldb           ExtraTreesRegressor(n_estimators=400, random_s...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### best_model_series ###\n",
        "\n",
        "\n",
        "# caco2_wang                   ExtraTreesRegressor(n_estimators=300, random_s...\n",
        "# lipophilicity_astrazeneca    AdaBoostRegressor(base_estimator=DecisionTreeR...\n",
        "# solubility_aqsoldb           ExtraTreesRegressor(n_estimators=400, random_s...\n",
        "# ppbr_az            (ExtraTreeRegressor(random_state=209652396), E...\n",
        "# vdss_lombardo      (DecisionTreeRegressor(random_state=209652396)...\n",
        "# half_life_obach    (DecisionTreeRegressor(random_state=209652396)...\n",
        "# clearance_microsome_az     (DecisionTreeRegressor(random_state=209652396)...\n",
        "# clearance_hepatocyte_az    (ExtraTreeRegressor(random_state=209652396), E...\n",
        "# ld50_zhu                   (DecisionTreeRegressor(max_features='auto', ra..."
      ],
      "metadata": {
        "id": "q_c9CnZYQ2zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb_4V-4GqYje",
        "outputId": "7b5f02c8-e22b-449d-b6f3-1d15ee273ee5"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ExtraTreesRegressor(n_estimators=300, random_state=0),\n",
              " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
              "                   n_estimators=450, random_state=0),\n",
              " ExtraTreesRegressor(n_estimators=400, random_state=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### best_model_list ###\n",
        "\n",
        "\n",
        "#[ExtraTreesRegressor(n_estimators=300, random_state=0),\n",
        "# AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
        "#                   n_estimators=450, random_state=0),\n",
        "# ExtraTreesRegressor(n_estimators=400, random_state=0)]\n",
        "# ExtraTreesRegressor(n_estimators=450, random_state=0),\n",
        "# AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.2,\n",
        "#                   n_estimators=450, random_state=0),\n",
        "# AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.05,\n",
        "#                   n_estimators=350, random_state=0)\n",
        "# AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), learning_rate=0.05,\n",
        "#                   n_estimators=200, random_state=0),\n",
        "# ExtraTreesRegressor(n_estimators=350, random_state=0),\n",
        "# RandomForestRegressor(n_estimators=400, random_state=0)]"
      ],
      "metadata": {
        "id": "GOQoTXuVDlwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Calculate performance of selected regression models"
      ],
      "metadata": {
        "id": "ubElLMdsEm_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "predictions_list = []\n",
        "\n",
        "regression_datasets = ['caco2_wang', \n",
        "                       'lipophilicity_astrazeneca', \n",
        "                       'solubility_aqsoldb', \n",
        "                       #'ppbr_az', \n",
        "                       #'vdss_lombardo', \n",
        "                       #'half_life_obach', \n",
        "                       #'clearance_microsome_az',\n",
        "                       #'clearance_hepatocyte_az', \n",
        "                       #'ld50_zhu'\n",
        "                      ]\n",
        "for seed in [1, 2, 3, 4, 5]:\n",
        "  predictions = {}\n",
        "  for reg in regression_datasets:\n",
        "    dataset = reg\n",
        "    benchmark = group.get(reg) \n",
        "    name = benchmark['name']\n",
        "    train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "    # split the train_val set into train & validation set\n",
        "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'scaffold', seed = seed)\n",
        "\n",
        "    x_train = molecular_descriptors(train)\n",
        "    x_valid = molecular_descriptors(valid)\n",
        "    x_test = molecular_descriptors(test)\n",
        "\n",
        "    # target column\n",
        "    y_train = train.Y\n",
        "    y_valid = valid.Y\n",
        "    y_test = test.Y\n",
        "\n",
        "    # merging traning and validation set\n",
        "    x_train_val = pd.concat([x_train, x_valid])\n",
        "    y_train_val = pd.concat([y_train, y_valid], axis=0)\n",
        "\n",
        "    # Replace NaN values with 0\n",
        "    x_train_val = np.nan_to_num(x_train_val, nan=0, posinf=0)\n",
        "    x_test = np.nan_to_num(x_test, nan=0, posinf=0)\n",
        "\n",
        "    # model training and prediction\n",
        "    model =  best_model_series[reg] \n",
        "\n",
        "    model.fit(x_train_val, y_train_val)\n",
        "    y_pred_test = model.predict(x_test)\n",
        "\n",
        "    predictions[name] = y_pred_test\n",
        "\n",
        "  predictions_list.append(predictions)\n",
        "\n",
        "results = group.evaluate_many(predictions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kgCKDvylnJV",
        "outputId": "a2684324-4d08-4e59-ab7b-66c9715c23af"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2236.05it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2460.90it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4787.74it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2215.21it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2318.23it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4696.27it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2283.71it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2449.52it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4698.00it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2267.59it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2472.14it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4703.17it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 728/728 [00:00<00:00, 2286.20it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 3360/3360 [00:01<00:00, 2453.38it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 7985/7985 [00:01<00:00, 4696.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHqTNjITP50u",
        "outputId": "4313cc01-c27b-452f-93cb-7c7a7b2c568c"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'caco2_wang': [0.323, 0.002],\n",
              " 'lipophilicity_astrazeneca': [0.615, 0.003],\n",
              " 'solubility_aqsoldb': [0.832, 0.003]}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#{'caco2_wang': [0.323, 0.002],                 (2)\n",
        "# 'lipophilicity_astrazeneca': [0.615, 0.003],  (8)\n",
        "# 'solubility_aqsoldb': [0.832, 0.003]          (3)\n",
        "# 'half_life_obach': [0.424, 0.013],            (1)\n",
        "# 'ppbr_az': [8.506, 0.034],                    (2)\n",
        "# 'vdss_lombardo': [0.545, 0.008]               (5)\n",
        "# 'clearance_hepatocyte_az': [0.442, 0.004],    (1)\n",
        "# 'clearance_microsome_az': [0.547, 0.011],     (6)\n",
        "# 'ld50_zhu': [0.639, 0.001]}                   (6)"
      ],
      "metadata": {
        "id": "CH_Dbx48QEzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Problems"
      ],
      "metadata": {
        "id": "PfCaeJegDkjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score as acc"
      ],
      "metadata": {
        "id": "CXE3pvkWk0YQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Search best ML models"
      ],
      "metadata": {
        "id": "dN7W13ZxFIvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "\n",
        "\n",
        "best_Cmodel_list = []\n",
        "\n",
        "classification_datasets = ['hia_hou', \n",
        "                       'pgp_broccatelli', \n",
        "                       'bioavailability_ma', \n",
        "                       'bbb_martins', \n",
        "                       'cyp2d6_veith', \n",
        "                       #'cyp3a4_veith', \n",
        "                       #'cyp2c9_veith',\n",
        "                       #'cyp2d6_substrate_carbonmangels', \n",
        "                       #'cyp3a4_substrate_carbonmangels',\n",
        "                       #'cyp2c9_substrate_carbonmangels',\n",
        "                       #'herg',\n",
        "                       #'ames',\n",
        "                       #'dili'\n",
        "                       ]\n",
        "\n",
        "for clf_data in classification_datasets:\n",
        "  \n",
        "  KNN = []\n",
        "  DT = []\n",
        "  Bag = []\n",
        "  RF = []\n",
        "  ET = []\n",
        "  AB = []\n",
        "  XG = []\n",
        "\n",
        "  benchmark = group.get(clf_data)\n",
        "  name = benchmark['name']\n",
        "\n",
        "  # split the dataset into train_val & test set\n",
        "  train_val, test = benchmark['train_val'], benchmark['test']\n",
        "\n",
        "  # feature extracting\n",
        "  x_train_val = molecular_descriptors(train_val)\n",
        "  x_test = molecular_descriptors(test)\n",
        "\n",
        "  # Replace NaN values with 0\n",
        "  x_train_val = np.nan_to_num(x_train_val, nan=0, posinf=0)\n",
        "  x_test = np.nan_to_num(x_test, nan=0, posinf=0)\n",
        "\n",
        "  # target data\n",
        "  y_train_val = train_val.Y\n",
        "  y_test = test.Y\n",
        "\n",
        "  # neighbors\n",
        "\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = knn.predict(x_test)\n",
        "  KNN.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  # tree\n",
        "\n",
        "  dt = DecisionTreeClassifier(random_state=0)\n",
        "  dt.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = dt.predict(x_test)\n",
        "  DT.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  # ensemble\n",
        "\n",
        "  bag = BaggingClassifier(DecisionTreeClassifier(), random_state=0)\n",
        "  bag.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = bag.predict(x_test)\n",
        "  Bag.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  rf = RandomForestClassifier(random_state=0)\n",
        "  rf.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = rf.predict(x_test)\n",
        "  RF.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  et = ExtraTreesClassifier(random_state=0)\n",
        "  et.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = et.predict(x_test)\n",
        "  ET.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  ada = AdaBoostClassifier(DecisionTreeClassifier(),random_state=0)\n",
        "  ada.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = ada.predict(x_test)\n",
        "  AB.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  xg = XGBClassifier(random_state=0)\n",
        "  xg.fit(x_train_val, y_train_val)\n",
        "  y_pred_test = xg.predict(x_test)\n",
        "  XG.append(acc(y_test, y_pred_test))\n",
        "\n",
        "  # Find out which model gives highest accuracy\n",
        "  a = []\n",
        "  models = ['K_Neighbors', 'Decision_Tree', 'Bagging', 'Random_Forest', 'Extra_Trees', 'Ada_Boost', 'XG_Boost']\n",
        "\n",
        "  for ml_acc in [KNN, DT, Bag, RF, ET, AB, XG]:\n",
        "    a.append(ml_acc)\n",
        "  a = pd.Series(a, index = models)\n",
        "\n",
        "  # Search best parameters of best_model for full train_val set\n",
        "  acc_tune = []\n",
        "  best_Cmodel_store = []\n",
        "\n",
        "  for high_acc in [-1, -2]:\n",
        "      best_model_name = a[a == np.sort(a)[high_acc][0]].index[0]\n",
        "\n",
        "      ml_Cmodel = [knn, dt, bag, rf, et, ada, xg]\n",
        "      best_model = ml_Cmodel[models.index(best_model_name)]\n",
        "\n",
        "      if best_model_name == 'Decision_Tree':\n",
        "        best_model = DecisionTreeClassifier(random_state=0)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "        acc_tune.append(DT[0])\n",
        "\n",
        "      elif best_model_name == 'K_Neighbors':\n",
        "        parameters = {'n_neighbors': np.arange(2,10,2)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_neighbors']\n",
        "\n",
        "        best_model = KNeighborsClassifier(n_neighbors = best_param)\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        acc_tune.append(acc(y_test, y_p))\n",
        "\n",
        "      elif best_model_name == 'Bagging' or best_model_name == 'Random_Forest' or best_model_name == 'Extra_Trees':\n",
        "        parameters = {'n_estimators': np.arange(100,550,50)}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param = rs_cv.best_params_['n_estimators']\n",
        "\n",
        "        if best_model_name == 'Bagging':\n",
        "          best_model = BaggingClassifier(DecisionTreeClassifier(), n_estimators = best_param, random_state=0)\n",
        "        elif best_model_name == 'Random_Forest':\n",
        "          best_model = RandomForestClassifier(n_estimators = best_param, random_state=0)\n",
        "        else:\n",
        "          best_model = ExtraTreesClassifier(n_estimators = best_param, random_state=0)\n",
        "\n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        acc_tune.append(acc(y_test, y_p))\n",
        "\n",
        "      else:\n",
        "        parameters = {'n_estimators': np.arange(100,550,50), 'learning_rate': [0.005, 0.05, 0.08, 0.1, 0.2, 0.3]}\n",
        "        rs_cv = RandomizedSearchCV(best_model, parameters)\n",
        "        rs_cv.fit(x_train_val, y_train_val)\n",
        "\n",
        "        best_param1 = rs_cv.best_params_['n_estimators']\n",
        "        best_param2 = rs_cv.best_params_['learning_rate']\n",
        "\n",
        "        if best_model_name == 'Ada_Boost':\n",
        "          best_model = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "        else:\n",
        "          best_model = XGBClassifier(n_estimators = best_param1, learning_rate = best_param2, random_state=0)\n",
        "          \n",
        "        best_Cmodel_store.append(best_model)\n",
        "\n",
        "        y_p = rs_cv.predict(x_test)\n",
        "        acc_tune.append(acc(y_test, y_p))\n",
        "\n",
        "  acc_tune_series = pd.Series(acc_tune, index = best_Cmodel_store)\n",
        "\n",
        "  best_Cmodel = acc_tune_series[acc_tune_series == max(acc_tune_series)].index[0]\n",
        "  best_Cmodel_list.append(best_model)\n",
        "\n",
        "best_Cmodel_series = pd.Series(best_Cmodel_list, index = classification_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uNhvL4gktV4",
        "outputId": "087467d8-4dfc-42a7-b2be-c2f78b6d1ba7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_Cmodel_series"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_UcTZxigjBf",
        "outputId": "1e2dca8f-0a81-4dbb-959d-6ebd0fd51c41"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "hia_hou                          DecisionTreeClassifier(random_state=0)\n",
              "pgp_broccatelli       ExtraTreesClassifier(n_estimators=250, random_...\n",
              "bioavailability_ma    ExtraTreesClassifier(n_estimators=450, random_...\n",
              "bbb_martins                        ExtraTreesClassifier(random_state=0)\n",
              "cyp2d6_veith          RandomForestClassifier(n_estimators=250, rando...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### best_Cmodel_series ###\n",
        "\n",
        "\n",
        "# hia_hou                          DecisionTreeClassifier(random_state=0)\n",
        "# pgp_broccatelli       ExtraTreesClassifier(n_estimators=250, random_...\n",
        "# bioavailability_ma    ExtraTreesClassifier(n_estimators=450, random_...\n",
        "# bbb_martins                        ExtraTreesClassifier(random_state=0)\n",
        "# cyp2d6_veith          RandomForestClassifier(n_estimators=250, rando...\n",
        "# cyp3a4_veith                      (ExtraTreeClassifier(random_state=209652396), ...\n",
        "# cyp2d6_substrate_carbonmangels    (DecisionTreeClassifier(random_state=208755735...\n",
        "# cyp3a4_substrate_carbonmangels    (DecisionTreeClassifier(max_features='auto', r...\n",
        "# cyp2c9_substrate_carbonmangels    (ExtraTreeClassifier(random_state=209652396), ...\n",
        "# ames    (DecisionTreeClassifier(max_features='auto', r...\n",
        "# dili    (DecisionTreeClassifier(max_features='auto', r...\n",
        "# herg    (ExtraTreeClassifier(random_state=209652396), ...\n",
        "# cyp2c9_veith    (DecisionTreeClassifier(random_state=209652396..."
      ],
      "metadata": {
        "id": "crgqrZzbM8ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_Cmodel_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpeWh_vH0ylR",
        "outputId": "83de2a6a-af54-40a6-8bad-33282a6a2275"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DecisionTreeClassifier(random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=250, random_state=0),\n",
              " ExtraTreesClassifier(n_estimators=450, random_state=0),\n",
              " ExtraTreesClassifier(random_state=0),\n",
              " RandomForestClassifier(n_estimators=250, random_state=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### best_Cmodel_list ###\n",
        "\n",
        "\n",
        "#[DecisionTreeClassifier(random_state=0),\n",
        "# ExtraTreesClassifier(n_estimators=250, random_state=0),\n",
        "# ExtraTreesClassifier(n_estimators=450, random_state=0),\n",
        "# ExtraTreesClassifier(random_state=0),\n",
        "# RandomForestClassifier(n_estimators=250, random_state=0),\n",
        "# ExtraTreesClassifier(n_estimators=450, random_state=0),\n",
        "# BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=150,\n",
        "#                   random_state=0),\n",
        "# RandomForestClassifier(random_state=0),\n",
        "# ExtraTreesClassifier(n_estimators=150, random_state=0)\n",
        "# RandomForestClassifier(n_estimators=500, random_state=0),\n",
        "# RandomForestClassifier(n_estimators=500, random_state=0)\n",
        "# ExtraTreesClassifier(n_estimators=350, random_state=0)\n",
        "# AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=0.1,\n",
        "#                    n_estimators=400, random_state=0)]"
      ],
      "metadata": {
        "id": "Sg28Eo_cMewx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Calculate performance of selected classification models"
      ],
      "metadata": {
        "id": "i6ICs8VFE6T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.benchmark_group import admet_group\n",
        "group = admet_group(path = 'data/')\n",
        "predictions_list = []\n",
        "\n",
        "classification_datasets = ['hia_hou', \n",
        "                       'pgp_broccatelli', \n",
        "                       'bioavailability_ma', \n",
        "                       'bbb_martins', \n",
        "                       'cyp2d6_veith', \n",
        "                       #'cyp3a4_veith', \n",
        "                       #'cyp2c9_veith',\n",
        "                       #'cyp2d6_substrate_carbonmangels', \n",
        "                       #'cyp3a4_substrate_carbonmangels',\n",
        "                       #'cyp2c9_substrate_carbonmangels',\n",
        "                       #'herg',\n",
        "                       #'ames',\n",
        "                       #'dili'\n",
        "                       ]\n",
        "\n",
        "\n",
        "for seed in [1, 2, 3, 4, 5]:\n",
        "    predictions = {}\n",
        "    for clf in classification_datasets:\n",
        "        dataset = clf\n",
        "        benchmark = group.get(clf) \n",
        "        name = benchmark['name']\n",
        "        train_val, test = benchmark['train_val'], benchmark['test']\n",
        "        train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
        "\n",
        "        ## --- train your model --- ##\n",
        "\n",
        "        x_train = molecular_descriptors(train)\n",
        "        y_train = train.Y\n",
        "        \n",
        "        x_valid = molecular_descriptors(valid)\n",
        "        y_valid = valid.Y\n",
        "\n",
        "        x_test = molecular_descriptors(test)\n",
        "        y_test = test.Y\n",
        "\n",
        "        # merging traning and validation set\n",
        "        x_train_val = pd.concat([x_train, x_valid])\n",
        "        y_train_val = pd.concat([y_train, y_valid], axis=0)\n",
        "\n",
        "        # Replace NaN values with 0\n",
        "        x_train_val = np.nan_to_num(x_train_val, nan=0, posinf=0)\n",
        "        x_test = np.nan_to_num(x_test, nan=0, posinf=0)\n",
        "\n",
        "        model = best_Cmodel_series[clf]       \n",
        "\n",
        "        model.fit(x_train_val, y_train_val)\n",
        "        y_pred_test = model.predict(x_test)\n",
        "        \n",
        "\n",
        "        predictions[name] = y_pred_test\n",
        "    predictions_list.append(predictions)\n",
        "\n",
        "results = group.evaluate_many(predictions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puOskhUqPJab",
        "outputId": "084a2d2e-3bae-4a9c-ee72-e64a096a4d47"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found local copy...\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3091.73it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2636.69it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 1724.54it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2806.27it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2667.76it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3324.33it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2596.81it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 3025.94it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 1815.19it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:06<00:00, 1602.58it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 1873.23it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:01<00:00, 804.45it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2950.86it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2821.92it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2647.42it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3149.01it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2532.45it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2948.17it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2875.92it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2710.31it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 461/461 [00:00<00:00, 3220.37it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 973/973 [00:00<00:00, 2540.46it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 512/512 [00:00<00:00, 2952.08it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 2770.48it/s]\n",
            "generating training, validation splits...\n",
            "100%|██████████| 10504/10504 [00:03<00:00, 2721.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUn46qUDCk64",
        "outputId": "1923cbe8-1c40-4b39-f222-d6c86ba4c41d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bbb_martins': [0.745, 0.0],\n",
              " 'bioavailability_ma': [0.583, 0.0],\n",
              " 'cyp2d6_veith': [0.365, 0.003],\n",
              " 'hia_hou': [0.856, 0.0],\n",
              " 'pgp_broccatelli': [0.822, 0.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRjT_4cbPyXi",
        "outputId": "50b0c734-1791-40e9-c726-27bbbfcd1496"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cyp2c9_veith': [0.532, 0.018], 'herg': [0.718, 0.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#{'bbb_martins': [0.745, 0.0],                        (x)\n",
        "# 'bioavailability_ma': [0.583, 0.0],                 (8)\n",
        "# 'cyp2d6_veith': [0.365, 0.003],                     (x)\n",
        "# 'hia_hou': [0.856, 0.0],                            (9)\n",
        "# 'pgp_broccatelli': [0.822, 0.0]                     (x)\n",
        "# 'cyp2c9_substrate_carbonmangels': [0.302, 0.0],     (x)\n",
        "# 'cyp2d6_substrate_carbonmangels': [0.476, 0.015],   (x)\n",
        "# 'cyp3a4_substrate_carbonmangels': [0.607, 0.017],   (7)\n",
        "# 'cyp3a4_veith': [0.637, 0.0]                        (x)\n",
        "# 'ames': [0.722, 0.003],                             (x)\n",
        "# 'dili': [0.824, 0.005]                              (10)\n",
        "# 'herg': [0.718, 0.0]                                (x)\n",
        "# 'cyp2c9_veith': [0.532, 0.018]}                     (x)"
      ],
      "metadata": {
        "id": "XFl_CQ8UHAgB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final_TDC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}